{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Suh_CaptionTrainer.ipynb","provenance":[{"file_id":"1h7X2h_b2_6jZ6bbmz9-cbLVAstZxFpru","timestamp":1617059199545}],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"CfOBqpb-8e0l","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617748859871,"user_tz":420,"elapsed":24129,"user":{"displayName":"Sanghyun Suh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUdCPmMsqijTthZ24MFHldVLUgCbJtwxfzXlusFw=s64","userId":"03325525587695274031"}},"outputId":"81f50fdb-3362-4c16-b4ab-5285687827d2"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Et2rQT9GBfwf","executionInfo":{"status":"ok","timestamp":1617748883826,"user_tz":420,"elapsed":362,"user":{"displayName":"Sanghyun Suh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUdCPmMsqijTthZ24MFHldVLUgCbJtwxfzXlusFw=s64","userId":"03325525587695274031"}},"outputId":"6b1ca796-ba54-4bc7-ad31-fcd787e18fbb"},"source":["%cd /content/drive/MyDrive/Image-Captioning-master"],"execution_count":3,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/Image-Captioning-master\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CqZxEehvBxzX","executionInfo":{"status":"ok","timestamp":1617748885604,"user_tz":420,"elapsed":908,"user":{"displayName":"Sanghyun Suh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUdCPmMsqijTthZ24MFHldVLUgCbJtwxfzXlusFw=s64","userId":"03325525587695274031"}},"outputId":"50b6f83c-7564-4b46-a108-df7e4dc97db7"},"source":["%tensorflow_version 1.x"],"execution_count":4,"outputs":[{"output_type":"stream","text":["TensorFlow 1.x selected.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8AxWstCrZNjD","executionInfo":{"status":"ok","timestamp":1617749017334,"user_tz":420,"elapsed":362,"user":{"displayName":"Sanghyun Suh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUdCPmMsqijTthZ24MFHldVLUgCbJtwxfzXlusFw=s64","userId":"03325525587695274031"}},"outputId":"194a2943-3900-47d3-fecd-a05bd3209882"},"source":["!python CapGenerator/prepare_data.py"],"execution_count":7,"outputs":[{"output_type":"stream","text":["python3: can't open file 'CapGenerator/prepare_data.py': [Errno 2] No such file or directory\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1299JsMTCB21","executionInfo":{"status":"ok","timestamp":1617749009109,"user_tz":420,"elapsed":369,"user":{"displayName":"Sanghyun Suh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUdCPmMsqijTthZ24MFHldVLUgCbJtwxfzXlusFw=s64","userId":"03325525587695274031"}},"outputId":"3d5957c9-cef4-4153-9ef0-3c8e056d33aa"},"source":["!python CapGenerator/train_model.py"],"execution_count":6,"outputs":[{"output_type":"stream","text":["python3: can't open file 'CapGenerator/train_model.py': [Errno 2] No such file or directory\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L0XmmwxQCMV8","executionInfo":{"status":"ok","timestamp":1616610202700,"user_tz":420,"elapsed":182637,"user":{"displayName":"Casey Rehm","photoUrl":"","userId":"14928713571001354102"}},"outputId":"a5fd3423-f7b5-43b1-f889-c3fcfdee755a"},"source":["!python CapGenerator/eval_modelMultiImage.py"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n","models/wholeModel.h5\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/keras/backend.py:3994: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","2021-03-24 18:20:23.605598: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n","2021-03-24 18:20:23.633972: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-03-24 18:20:23.634622: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\n","pciBusID: 0000:00:04.0\n","2021-03-24 18:20:23.634921: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2021-03-24 18:20:23.636652: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2021-03-24 18:20:23.638322: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2021-03-24 18:20:23.638662: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2021-03-24 18:20:23.640172: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2021-03-24 18:20:23.640848: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2021-03-24 18:20:23.652465: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2021-03-24 18:20:23.652632: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-03-24 18:20:23.653374: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-03-24 18:20:23.653917: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2021-03-24 18:20:23.654323: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX512F\n","2021-03-24 18:20:23.662469: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000200000 Hz\n","2021-03-24 18:20:23.662753: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55a69ac9d500 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n","2021-03-24 18:20:23.662781: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n","2021-03-24 18:20:23.749410: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-03-24 18:20:23.750301: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55a69ac9d6c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2021-03-24 18:20:23.750340: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-16GB, Compute Capability 7.0\n","2021-03-24 18:20:23.750525: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-03-24 18:20:23.751127: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\n","pciBusID: 0000:00:04.0\n","2021-03-24 18:20:23.751205: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2021-03-24 18:20:23.751223: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2021-03-24 18:20:23.751235: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2021-03-24 18:20:23.751250: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2021-03-24 18:20:23.751264: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2021-03-24 18:20:23.751277: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2021-03-24 18:20:23.751292: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2021-03-24 18:20:23.751368: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-03-24 18:20:23.752026: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-03-24 18:20:23.752630: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2021-03-24 18:20:23.752717: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2021-03-24 18:20:23.754005: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2021-03-24 18:20:23.754033: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n","2021-03-24 18:20:23.754053: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n","2021-03-24 18:20:23.754181: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-03-24 18:20:23.754831: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-03-24 18:20:23.755428: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2021-03-24 18:20:23.755478: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15060 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0)\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","361\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n","\n","2021-03-24 18:20:27.658367: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2021-03-24 18:20:27.842376: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","out256_00_02.png: of\n","out256_00_07.png: of\n","out256_00_09.png: of\n","out256_00_03.png: of\n","out256_00_05.png: of\n","out256_00_08.png: of\n","out256_00_06.png: of\n","out256_00_10.png: of\n","out256_00_04.png: of\n","out256_00_01.png: of\n","out256_00_00.png: of\n","out256_01_01.png: of\n","out256_00_11.png: of\n","out256_01_12.png: of\n","out256_01_06.png: of\n","out256_01_11.png: of\n","out256_01_07.png: of\n","out256_00_18.png: of\n","out256_01_09.png: of\n","out256_00_13.png: of\n","out256_01_13.png: of\n","out256_01_05.png: of\n","out256_01_02.png: of\n","out256_01_14.png: of\n","out256_00_14.png: of\n","out256_01_08.png: of\n","out256_00_17.png: of\n","out256_01_10.png: of\n","out256_01_03.png: of\n","out256_00_12.png: of\n","out256_01_04.png: of\n","out256_00_15.png: of\n","out256_00_16.png: of\n","out256_01_00.png: of\n","out256_02_06.png: of\n","out256_01_17.png: of\n","out256_01_18.png: of\n","out256_02_07.png: of\n","out256_02_00.png: of\n","out256_02_13.png: of\n","out256_02_05.png: of\n","out256_02_12.png: of\n","out256_01_15.png: of\n","out256_02_09.png: of\n","out256_02_03.png: of\n","out256_02_17.png: of\n","out256_02_02.png: of\n","out256_02_16.png: of\n","out256_02_01.png: of\n","out256_02_14.png: of\n","out256_02_10.png: of\n","out256_02_08.png: of\n","out256_01_16.png: of\n","out256_02_11.png: of\n","out256_02_15.png: of\n","out256_02_04.png: of\n","out256_03_00.png: of\n","out256_03_04.png: of\n","out256_03_03.png: of\n","out256_03_14.png: of\n","out256_03_10.png: of\n","out256_03_12.png: of\n","out256_03_02.png: of\n","out256_03_18.png: of\n","out256_03_09.png: of\n","out256_03_05.png: of\n","out256_03_08.png: of\n","out256_03_06.png: of\n","out256_03_16.png: of\n","out256_03_13.png: of\n","out256_03_17.png: of\n","out256_02_18.png: of\n","out256_03_15.png: of\n","out256_03_11.png: of\n","out256_04_00.png: of\n","out256_03_07.png: of\n","out256_03_01.png: of\n","out256_04_04.png: of\n","out256_04_03.png: of\n","out256_04_05.png: of\n","out256_04_18.png: of\n","out256_04_07.png: of\n","out256_05_00.png: of\n","out256_04_06.png: of\n","out256_04_10.png: of\n","out256_04_12.png: of\n","out256_04_09.png: of\n","out256_05_03.png: of\n","out256_04_16.png: of\n","out256_04_01.png: of\n","out256_04_14.png: of\n","out256_04_17.png: of\n","out256_05_02.png: of\n","out256_04_11.png: of\n","out256_04_02.png: of\n","out256_05_01.png: of\n","out256_04_08.png: of\n","out256_04_15.png: of\n","out256_04_13.png: of\n","out256_05_12.png: of\n","out256_05_09.png: of\n","out256_05_18.png: of\n","out256_05_08.png: of\n","out256_05_17.png: of\n","out256_06_02.png: of\n","out256_05_14.png: of\n","out256_05_06.png: of\n","out256_06_03.png: of\n","out256_06_00.png: of\n","out256_05_16.png: of\n","out256_05_13.png: of\n","out256_06_01.png: of\n","out256_05_15.png: of\n","out256_06_05.png: of\n","out256_05_11.png: of\n","out256_05_04.png: of\n","out256_06_04.png: of\n","out256_05_05.png: of\n","out256_05_10.png: of\n","out256_05_07.png: of\n","out256_07_07.png: of\n","out256_07_04.png: of\n","out256_06_09.png: of\n","out256_06_14.png: of\n","out256_06_06.png: of\n","out256_07_02.png: of\n","out256_07_06.png: of\n","out256_06_07.png: of\n","out256_06_15.png: of\n","out256_07_05.png: of\n","out256_06_11.png: of\n","out256_07_03.png: of\n","out256_06_16.png: of\n","out256_06_10.png: of\n","out256_07_01.png: of\n","out256_06_12.png: of\n","out256_07_00.png: of\n","out256_06_08.png: of\n","out256_06_17.png: of\n","out256_06_13.png: of\n","out256_06_18.png: of\n","out256_08_03.png: of\n","out256_08_01.png: of\n","out256_07_18.png: of\n","out256_08_00.png: of\n","out256_08_09.png: of\n","out256_07_11.png: of\n","out256_08_05.png: of\n","out256_07_13.png: of\n","out256_07_12.png: of\n","out256_08_08.png: of\n","out256_07_17.png: of\n","out256_08_06.png: of\n","out256_07_10.png: of\n","out256_08_04.png: of\n","out256_07_08.png: of\n","out256_07_14.png: of\n","out256_08_02.png: of\n","out256_07_15.png: of\n","out256_07_16.png: of\n","out256_07_09.png: of\n","out256_08_07.png: of\n","out256_08_13.png: of\n","out256_09_10.png: of\n","out256_08_18.png: of\n","out256_09_11.png: of\n","out256_08_15.png: of\n","out256_09_02.png: of\n","out256_09_08.png: of\n","out256_09_09.png: of\n","out256_09_12.png: of\n","out256_08_16.png: of\n","out256_09_13.png: of\n","out256_08_11.png: of\n","out256_08_12.png: of\n","out256_08_17.png: of\n","out256_09_04.png: of\n","out256_09_05.png: of\n","out256_09_01.png: of\n","out256_09_00.png: of\n","out256_09_06.png: of\n","out256_09_03.png: of\n","out256_09_07.png: of\n","out256_08_10.png: of\n","out256_08_14.png: of\n","out256_09_14.png: of\n","out256_10_03.png: of\n","out256_10_05.png: of\n","out256_10_14.png: of\n","out256_10_12.png: of\n","out256_10_08.png: of\n","out256_10_10.png: of\n","out256_10_09.png: of\n","out256_10_04.png: of\n","out256_10_16.png: of\n","out256_10_13.png: of\n","out256_10_01.png: of\n","out256_09_18.png: of\n","out256_09_17.png: of\n","out256_10_06.png: of\n","out256_10_15.png: of\n","out256_10_00.png: of\n","out256_10_02.png: of\n","out256_09_15.png: of\n","out256_09_16.png: of\n","out256_10_07.png: of\n","out256_10_11.png: of\n","out256_11_14.png: of\n","out256_11_03.png: of\n","out256_11_09.png: of\n","out256_10_18.png: of\n","out256_11_02.png: of\n","out256_11_04.png: of\n","out256_11_16.png: of\n","out256_11_08.png: of\n","out256_11_07.png: of\n","out256_11_17.png: of\n","out256_11_12.png: of\n","out256_11_18.png: of\n","out256_10_17.png: of\n","out256_11_00.png: of\n","out256_11_01.png: of\n","out256_11_15.png: of\n","out256_11_06.png: of\n","out256_11_05.png: of\n","out256_11_10.png: of\n","out256_11_11.png: of\n","out256_11_13.png: of\n","out256_13_02.png: of\n","out256_12_02.png: of\n","out256_13_01.png: of\n","out256_12_09.png: of\n","out256_12_04.png: of\n","out256_12_07.png: of\n","out256_12_05.png: of\n","out256_12_13.png: of\n","out256_12_14.png: of\n","out256_12_16.png: of\n","out256_12_18.png: of\n","out256_12_15.png: of\n","out256_12_03.png: of\n","out256_12_17.png: of\n","out256_12_00.png: of\n","out256_13_00.png: of\n","out256_12_01.png: of\n","out256_12_10.png: of\n","out256_12_12.png: of\n","out256_12_06.png: of\n","out256_12_11.png: of\n","out256_12_08.png: of\n","out256_13_06.png: of\n","out256_13_08.png: of\n","out256_13_12.png: of\n","out256_14_03.png: of\n","out256_13_10.png: of\n","out256_14_02.png: of\n","out256_13_04.png: of\n","out256_13_05.png: of\n","out256_13_14.png: of\n","out256_14_01.png: of\n","out256_14_04.png: of\n","out256_13_17.png: of\n","out256_13_16.png: of\n","out256_14_05.png: of\n","out256_13_15.png: of\n","out256_13_18.png: of\n","out256_13_07.png: of\n","out256_13_13.png: of\n","out256_13_09.png: of\n","out256_14_00.png: of\n","out256_13_11.png: of\n","out256_13_03.png: of\n","out256_14_06.png: of\n","out256_14_14.png: of\n","out256_14_07.png: of\n","out256_14_10.png: of\n","out256_15_03.png: of\n","out256_15_08.png: of\n","out256_14_13.png: of\n","out256_14_09.png: of\n","out256_14_08.png: of\n","out256_14_16.png: of\n","out256_15_06.png: of\n","out256_15_07.png: of\n","out256_15_01.png: of\n","out256_14_17.png: of\n","out256_14_11.png: of\n","out256_15_02.png: of\n","out256_15_05.png: of\n","out256_14_12.png: of\n","out256_15_00.png: of\n","out256_15_04.png: of\n","out256_14_15.png: of\n","out256_15_09.png: of\n","out256_14_18.png: of\n","out256_16_02.png: of\n","out256_15_12.png: of\n","out256_15_10.png: of\n","Traceback (most recent call last):\n","  File \"CapGenerator/eval_modelMultiImage.py\", line 111, in <module>\n","    photo = extract_features(fileN, m)\n","  File \"CapGenerator/eval_modelMultiImage.py\", line 22, in extract_features\n","    image = load_img(filename, target_size=(224, 224))\n","  File \"/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/utils.py\", line 114, in load_img\n","    img = pil_image.open(io.BytesIO(f.read()))\n","KeyboardInterrupt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OOqbE6yvRDDZ","executionInfo":{"status":"ok","timestamp":1616615413611,"user_tz":420,"elapsed":513,"user":{"displayName":"Casey Rehm","photoUrl":"","userId":"14928713571001354102"}},"outputId":"11bc8da7-b058-4e5c-ce4b-8bf2c2a41173"},"source":["%cd /content/drive/MyDrive/googleDataset"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/googleDataset\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ejw3Cja4K5Bf"},"source":["import os\n","import PIL.Image\n","import urllib.request\n","import pandas as pd\n","import requests\n","import shutil\n","import csv\n","\n","def resize_and_crop(img, size):\n","\n","\n","    # Get current and desired ratio for the images\n","    img_ratio = img.size[0] / float(img.size[1])\n","    ratio = size[0] / float(size[1])\n","    #The image is scaled/cropped vertically or horizontally depending on the ratio\n","    if ratio > img_ratio:\n","        img = img.resize((size[0], int(size[0] * img.size[1] / img.size[0])), PIL.Image.ANTIALIAS)\n","        box = (0, (img.size[1] - size[1]) / 2, img.size[0], (img.size[1] + size[1]) / 2)\n","        img = img.crop(box)\n","    elif ratio < img_ratio:\n","        img = img.resize((int(size[1] * img.size[0] / img.size[1]), size[1]), PIL.Image.ANTIALIAS)\n","        box = ((img.size[0] - size[0]) / 2, 0, (img.size[0] + size[0]) / 2, img.size[1])\n","        img = img.crop(box)\n","    else :\n","        img = img.resize((size[0], size[1]),PIL.Image.ANTIALIAS)\n","        # If the scale is the same, we do not need to crop\n","    return img\n","\n","def main():\n","    DIR = 'formatted'\n","    data = pd.read_table(\"Train_GCC-training.tsv\", usecols=[0,1], names=['caption', 'url'], header=None)\n","    txtFile = open('imageCaptions.txt', 'w', newline='')\n","    #print(data)\n","    for i in range(20000):\n","        t = \"{:05d}\".format(i)\n","        fName = 'gImg_' + t + '.png'\n","        cap = data['caption'][i]\n","        url = data['url'][i]\n","\n","        #urllib.request.urlretrieve(url,fName)\n","        try:            \n","            image = PIL.Image.open(requests.get(url, stream=True, timeout=10).raw)\n","            image = resize_and_crop(image, [244, 244])\n","            if image.mode != 'RGB':\n","                image = image.convert('RGB')\n","            image.save(DIR + '/' + fName)\n","            txtFile.write(fName + ',' + cap)\n","            txtFile.write('\\n')\n","            \n","    \n","        except:\n","\n","            continue\n","\n","\n","\n","\n","    txtFile.close()\n","\n","\n","\n","\n","\n","if __name__ == \"__main__\":\n","    main()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-ypoO8oKYbrw","executionInfo":{"status":"ok","timestamp":1616615392289,"user_tz":420,"elapsed":16456,"user":{"displayName":"Casey Rehm","photoUrl":"","userId":"14928713571001354102"}},"outputId":"303b418b-186d-4c18-ccbd-ea0d33c65fe6"},"source":["!apt install -qq enchant\n","!pip install pyenchant"],"execution_count":null,"outputs":[{"output_type":"stream","text":["The following additional packages will be installed:\n","  aspell aspell-en dictionaries-common emacsen-common hunspell-en-us\n","  libaspell15 libenchant1c2a libhunspell-1.6-0 libtext-iconv-perl\n","Suggested packages:\n","  aspell-doc spellutils wordlist hunspell openoffice.org-hunspell\n","  | openoffice.org-core libenchant-voikko\n","The following NEW packages will be installed:\n","  aspell aspell-en dictionaries-common emacsen-common enchant hunspell-en-us\n","  libaspell15 libenchant1c2a libhunspell-1.6-0 libtext-iconv-perl\n","0 upgraded, 10 newly installed, 0 to remove and 30 not upgraded.\n","Need to get 1,310 kB of archives.\n","After this operation, 5,353 kB of additional disk space will be used.\n","Preconfiguring packages ...\n","Selecting previously unselected package libtext-iconv-perl.\n","(Reading database ... 160980 files and directories currently installed.)\n","Preparing to unpack .../0-libtext-iconv-perl_1.7-5build6_amd64.deb ...\n","Unpacking libtext-iconv-perl (1.7-5build6) ...\n","Selecting previously unselected package libaspell15:amd64.\n","Preparing to unpack .../1-libaspell15_0.60.7~20110707-4ubuntu0.1_amd64.deb ...\n","Unpacking libaspell15:amd64 (0.60.7~20110707-4ubuntu0.1) ...\n","Selecting previously unselected package emacsen-common.\n","Preparing to unpack .../2-emacsen-common_2.0.8_all.deb ...\n","Unpacking emacsen-common (2.0.8) ...\n","Selecting previously unselected package dictionaries-common.\n","Preparing to unpack .../3-dictionaries-common_1.27.2_all.deb ...\n","Adding 'diversion of /usr/share/dict/words to /usr/share/dict/words.pre-dictionaries-common by dictionaries-common'\n","Unpacking dictionaries-common (1.27.2) ...\n","Selecting previously unselected package aspell.\n","Preparing to unpack .../4-aspell_0.60.7~20110707-4ubuntu0.1_amd64.deb ...\n","Unpacking aspell (0.60.7~20110707-4ubuntu0.1) ...\n","Selecting previously unselected package aspell-en.\n","Preparing to unpack .../5-aspell-en_2017.08.24-0-0.1_all.deb ...\n","Unpacking aspell-en (2017.08.24-0-0.1) ...\n","Selecting previously unselected package hunspell-en-us.\n","Preparing to unpack .../6-hunspell-en-us_1%3a2017.08.24_all.deb ...\n","Unpacking hunspell-en-us (1:2017.08.24) ...\n","Selecting previously unselected package libhunspell-1.6-0:amd64.\n","Preparing to unpack .../7-libhunspell-1.6-0_1.6.2-1_amd64.deb ...\n","Unpacking libhunspell-1.6-0:amd64 (1.6.2-1) ...\n","Selecting previously unselected package libenchant1c2a:amd64.\n","Preparing to unpack .../8-libenchant1c2a_1.6.0-11.1_amd64.deb ...\n","Unpacking libenchant1c2a:amd64 (1.6.0-11.1) ...\n","Selecting previously unselected package enchant.\n","Preparing to unpack .../9-enchant_1.6.0-11.1_amd64.deb ...\n","Unpacking enchant (1.6.0-11.1) ...\n","Setting up libhunspell-1.6-0:amd64 (1.6.2-1) ...\n","Setting up libaspell15:amd64 (0.60.7~20110707-4ubuntu0.1) ...\n","Setting up emacsen-common (2.0.8) ...\n","Setting up libtext-iconv-perl (1.7-5build6) ...\n","Setting up dictionaries-common (1.27.2) ...\n","Setting up aspell (0.60.7~20110707-4ubuntu0.1) ...\n","Setting up hunspell-en-us (1:2017.08.24) ...\n","Setting up libenchant1c2a:amd64 (1.6.0-11.1) ...\n","Setting up aspell-en (2017.08.24-0-0.1) ...\n","Setting up enchant (1.6.0-11.1) ...\n","Processing triggers for libc-bin (2.27-3ubuntu1.2) ...\n","/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n","\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n","Processing triggers for dictionaries-common (1.27.2) ...\n","aspell-autobuildhash: processing: en [en-common].\n","aspell-autobuildhash: processing: en [en-variant_0].\n","aspell-autobuildhash: processing: en [en-variant_1].\n","aspell-autobuildhash: processing: en [en-variant_2].\n","aspell-autobuildhash: processing: en [en-w_accents-only].\n","aspell-autobuildhash: processing: en [en-wo_accents-only].\n","aspell-autobuildhash: processing: en [en_AU-variant_0].\n","aspell-autobuildhash: processing: en [en_AU-variant_1].\n","aspell-autobuildhash: processing: en [en_AU-w_accents-only].\n","aspell-autobuildhash: processing: en [en_AU-wo_accents-only].\n","aspell-autobuildhash: processing: en [en_CA-variant_0].\n","aspell-autobuildhash: processing: en [en_CA-variant_1].\n","aspell-autobuildhash: processing: en [en_CA-w_accents-only].\n","aspell-autobuildhash: processing: en [en_CA-wo_accents-only].\n","aspell-autobuildhash: processing: en [en_GB-ise-w_accents-only].\n","aspell-autobuildhash: processing: en [en_GB-ise-wo_accents-only].\n","aspell-autobuildhash: processing: en [en_GB-ize-w_accents-only].\n","aspell-autobuildhash: processing: en [en_GB-ize-wo_accents-only].\n","aspell-autobuildhash: processing: en [en_GB-variant_0].\n","aspell-autobuildhash: processing: en [en_GB-variant_1].\n","aspell-autobuildhash: processing: en [en_US-w_accents-only].\n","aspell-autobuildhash: processing: en [en_US-wo_accents-only].\n","Collecting pyenchant\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/8c/bd224a5db562ac008edbfaf015f5d5c98ea13e745247cd4ab5fc5b683085/pyenchant-3.2.0-py3-none-any.whl (55kB)\n","\u001b[K     |████████████████████████████████| 61kB 4.6MB/s \n","\u001b[?25hInstalling collected packages: pyenchant\n","Successfully installed pyenchant-3.2.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JHuply9qVFky","colab":{"base_uri":"https://localhost:8080/","height":336},"executionInfo":{"status":"error","timestamp":1616615446739,"user_tz":420,"elapsed":1998,"user":{"displayName":"Casey Rehm","photoUrl":"","userId":"14928713571001354102"}},"outputId":"1139053d-ccbd-4a6e-f5ca-a33e4fc5fe98"},"source":["import enchant\n","import string\n","import random\n","import shutil\n","import os\n","\n","def main():\n","    en_us = enchant.Dict(\"en_US\")\n","    txtFile = open('imageCaptions.txt', 'r')\n","    trainFile = open('trainImages.txt', 'w')\n","    devFile = open('devImages.txt', 'w')\n","    fixFile = open('fixedCaptions.txt', 'w')\n","    lines = txtFile.readlines()\n","    DIR= 'Flickr8k_Dataset'\n","    SDIR = 'target'\n","    fList = []\n","    for i in range(0,10000):\n","        row = lines[i].split(',')\n","        if len(row)>1:\n","            if '.png' in row[0]:\n","                fList.append(row[0])\n","                if len(row) == 2:\n","                    newStr = row[1]\n","                    tempStr = newStr.split()\n","                    newStr = \"\"\n","                    for j in range(len(tempStr)):\n","                        if j < 10:\n","                            newStr = newStr + ' ' + tempStr[j]\n","                    newStr = ' '.join(w for w in newStr.split() if en_us.check(w))\n","                    newStr = newStr.replace('\\n','')\n","                    exclude = set(string.punctuation)\n","                    newStr = ''.join(ch for ch in newStr if ch not in exclude)\n","                    fixFile.write(row[0] + ' ' + newStr)\n","                    if random.random() < .2:\n","                        devFile.write(row[0])\n","                        if i < len(lines)-1:\n","                            devFile.write('\\n')\n","                    else:\n","                        trainFile.write(row[0])\n","                        if i < len(lines)-1:\n","                            trainFile.write('\\n')\n","\n","                else:\n","                    newStr = \"\"\n","                    for j in range(1,len(row)):\n","                        newStr = newStr + row[j]\n","                    tempStr = newStr.split()\n","                    newStr = \"\"\n","                    for j in range(len(tempStr)):\n","                        if j < 10:\n","                            newStr = newStr + ' ' + tempStr[j]\n","                    newStr = ' '.join(w for w in newStr.split() if en_us.check(w))\n","                    newStr = newStr.replace('\\n','')\n","                    exclude = set(string.punctuation)\n","                    newStr = ''.join(ch for ch in newStr if ch not in exclude)\n","                    fixFile.write(row[0] + ' ' + newStr)\n","\n","\n","                if i < len(lines)-1:\n","                    fixFile.write('\\n')\n","    \n","    for i in range(10000,len(lines)):\n","        row = lines[i].split(',')\n","        if '.png' in row[0]:\n","            source = DIR+'/'+row[0]\n","            try:\n","                os.remove(source)\n","                print(row[0])\n","            except:\n","                continue\n","\n","    fList = list(set(fList))\n","    for i in range(len(fList)):\n","        if random.random() < .9:\n","            trainFile.write(fList[i])\n","            trainFile.write('\\n')\n","        else:\n","            devFile.write(fList[i])\n","            devFile.write('\\n')\n","\n","    fixFile.close()\n","    trainFile.close()\n","    devFile.close()\n","    txtFile.close()\n","\n","if __name__ == \"__main__\":\n","    main()"],"execution_count":null,"outputs":[{"output_type":"error","ename":"IndexError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-107ed65a6e0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-6-107ed65a6e0d>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mfList\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m'.png'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: list index out of range"]}]},{"cell_type":"code","metadata":{"id":"aV-qVSLjYVGY"},"source":[""],"execution_count":null,"outputs":[]}]}
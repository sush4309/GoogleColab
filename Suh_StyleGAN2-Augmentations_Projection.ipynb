{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Suh_StyleGAN2-Augmentations_Projection.ipynb","provenance":[{"file_id":"1jmMGOTDM0Y3ftbaGKEXwsr6bViBMxdE0","timestamp":1615953078629},{"file_id":"1UPZWAiXDllrpiGbGMLMHtSxZ2MnALZ1G","timestamp":1614052722802},{"file_id":"https://github.com/dvschultz/ai/blob/master/StyleGAN2_Augmentations.ipynb","timestamp":1597692261353}],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"LvKaOmgoWAsI"},"source":["# StyleGAN2 with Augmentations\n","\n","This notebook shows code for training with image augmentations. For more info on this technique see [Training Generative Adversarial Networks with Limited Data](https://arxiv.org/abs/2006.06676). \n","\n","This code comes from [Sid Black](https://github.com/sdtblck/stylegan2). A huge thanks to him for doing all of this work üôè\n","\n","If this is your first time using StyleGAN2 on Colab I recommend watching some of my YouTube videos first. Start with [this one](https://www.youtube.com/watch?v=hv3A62Ojqdg). A video on this notebook and technique is [here](https://youtu.be/D3a9DFykfxI)"]},{"cell_type":"code","metadata":{"id":"9QtGFQ_PwLFZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615952300495,"user_tz":420,"elapsed":967,"user":{"displayName":"Casey Rehm","photoUrl":"","userId":"14928713571001354102"}},"outputId":"2c653067-00b7-4ce7-8efd-bf94e4d0542a"},"source":["#always use tensorflow1\n","\n","%tensorflow_version 1.x\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["TensorFlow 1.x selected.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Gdl_HcPhkTsv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615952329358,"user_tz":420,"elapsed":27233,"user":{"displayName":"Casey Rehm","photoUrl":"","userId":"14928713571001354102"}},"outputId":"a24d82e8-a288-4923-ff88-178af728cdd8"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"6I1rJ72VWSY6"},"source":["## Initial Setup\n","\n","Run this cell if you‚Äôve never run this repo in your Drive account. SKIP it if you have."]},{"cell_type":"code","metadata":{"id":"7lSz-7VCkmaK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611367326763,"user_tz":480,"elapsed":26831,"user":{"displayName":"Casey Rehm","photoUrl":"","userId":"14928713571001354102"}},"outputId":"920c9938-4960-4730-8e9d-57bac7c8fb3d"},"source":["#SKIP this if you already have a stylegan2 folder in your google drive\n","%cd /content/drive/MyDrive/\n","!mkdir stylegan2-aug-colab\n","%cd stylegan2-aug-colab/\n","!git clone -b augs-attn https://github.com/dvschultz/stylegan2\n","%cd stylegan2\n","!mkdir pkl\n","%cd pkl\n","!gdown --id 1JLqXE5bGZnlu2BkbLPD5_ZxoO3Nz-AvF #inception: https://drive.google.com/open?id=1JLqXE5bGZnlu2BkbLPD5_ZxoO3Nz-AvF\n","%cd ../\n","!mkdir results\n","!mkdir results/00001-pretrained\n","%cd results/00001-pretrained\n","!gdown --id 1UlDmJVLLnBD9SnLSMXeiZRO6g-OMQCA_\n","%cd ../../\n","%mkdir datasets"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive\n","mkdir: cannot create directory ‚Äòstylegan2-aug-colab‚Äô: File exists\n","/content/drive/MyDrive/stylegan2-aug-colab\n","fatal: destination path 'stylegan2' already exists and is not an empty directory.\n","/content/drive/MyDrive/stylegan2-aug-colab/stylegan2\n","mkdir: cannot create directory ‚Äòpkl‚Äô: File exists\n","/content/drive/MyDrive/stylegan2-aug-colab/stylegan2/pkl\n","Downloading...\n","From: https://drive.google.com/uc?id=1JLqXE5bGZnlu2BkbLPD5_ZxoO3Nz-AvF\n","To: /content/drive/MyDrive/stylegan2-aug-colab/stylegan2/pkl/inception_v3_features.pkl\n","87.3MB [00:01, 63.9MB/s]\n","/content/drive/My Drive/stylegan2-aug-colab/stylegan2\n","mkdir: cannot create directory ‚Äòresults‚Äô: File exists\n","mkdir: cannot create directory ‚Äòresults/00001-pretrained‚Äô: File exists\n","/content/drive/My Drive/stylegan2-aug-colab/stylegan2/results/00001-pretrained\n","Downloading...\n","From: https://drive.google.com/uc?id=1UlDmJVLLnBD9SnLSMXeiZRO6g-OMQCA_\n","To: /content/drive/My Drive/stylegan2-aug-colab/stylegan2/results/00001-pretrained/stylegan2-ffhq-config-f.pkl\n","382MB [00:03, 97.3MB/s]\n","/content/drive/My Drive/stylegan2-aug-colab/stylegan2\n","mkdir: cannot create directory ‚Äòdatasets‚Äô: File exists\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"BsQL8nw9WX6C"},"source":["## Return Setup\n","Run this cell if you‚Äôre picking up from a previous training."]},{"cell_type":"code","metadata":{"id":"w9tLYIpHk8WU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615952335285,"user_tz":420,"elapsed":693,"user":{"displayName":"Casey Rehm","photoUrl":"","userId":"14928713571001354102"}},"outputId":"ab3ce533-8875-4370-f755-87c985607ad6"},"source":["%cd /content/drive/MyDrive/stylegan2-aug-colab/stylegan2\n","#!git pull"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/stylegan2-aug-colab/stylegan2\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"2qbCFYx3Wghn"},"source":["## Training\n","\n","In the next cell set your pkl and `resume_kimg` counter. If this is your first time the settings below should work for you."]},{"cell_type":"code","metadata":{"id":"83hg9Jw9zObb"},"source":["pkl = \"/content/drive/MyDrive/LABestia/pretrainedCheckpoints/ffhq-512-avg-tpurun1.pkl\"\n","resume_kimg = 10000"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fWf6qqV_-UQP"},"source":["if you need to make a dataset run below\n"]},{"cell_type":"markdown","metadata":{"id":"_jN99nH6Ep1S"},"source":["The first address is the destination tf Records file"]},{"cell_type":"code","metadata":{"id":"nHtOsDri-YNm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615917838362,"user_tz":420,"elapsed":398484,"user":{"displayName":"Casey Rehm","photoUrl":"","userId":"14928713571001354102"}},"outputId":"f16915e1-12ef-4e64-a447-5c34bf480262"},"source":["!python dataset_tool.py create_from_images_raw /content/drive/MyDrive/stylegan2-aug-colab/stylegan2/datasets/CLDSpatial /content/drive/MyDrive/LABestiaTeam/datasets/512ImageSets/3WaySpatial"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Loading images from \"/content/drive/MyDrive/LABestiaTeam/datasets/512ImageSets/3WaySpatial\"\n","detected 1056 images ...\n","Shuffle the images...\n","Creating dataset \"/content/drive/MyDrive/stylegan2-aug-colab/stylegan2/datasets/CLDSpatial\"\n","Adding the images to tfrecords ...\n","added images 0\n","added images 1000\n","Added 1056 images.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"EQDK-iofWls5"},"source":["Most of the settings match the skyflynil or pbaylies fork of StyleGAN2. The big difference here is the `AUG_PROB` environment setting. This tells the training loop how often to modify the real and fake images with augmentations. The default is `0.1` If you have a small training set you may want to go higher than that but note that the Karras paper does say if you set this value too high you may find it bleeds into the outputs."]},{"cell_type":"code","metadata":{"id":"LqZAM9ormiYf","colab":{"base_uri":"https://localhost:8080/"},"outputId":"882f2c5c-dcac-497b-ba6f-bd4f85bedd80"},"source":["!AUG_PROB=0.2 python run_training.py --num-gpus=1 --mirror-augment=True --data-dir=./datasets --dataset=Beast --config=config-f --resume-pkl=$pkl --resume-kimg=$resume_kimg --augmentations=True --metrics=None"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Local submit - run_dir: results/00052-stylegan2-Beast-1gpu-config-f\n","dnnlib: Running training.training_loop.training_loop() on localhost...\n","Streaming data using training.dataset.TFRecordDataset...\n","Dataset shape = [3, 512, 512]\n","Dynamic range = [0, 255]\n","Label size    = 0\n","Loading networks from \"/content/drive/MyDrive/LABestia/pretrainedCheckpoints/ffhq-512-avg-tpurun1.pkl\"...\n","Setting up TensorFlow plugin \"fused_bias_act.cu\": Preprocessing... Loading... Done.\n","Setting up TensorFlow plugin \"upfirdn_2d.cu\": Preprocessing... Loading... Done.\n","\n","G                             Params    OutputShape         WeightShape     \n","---                           ---       ---                 ---             \n","latents_in                    -         (?, 512)            -               \n","labels_in                     -         (?, 0)              -               \n","lod                           -         ()                  -               \n","dlatent_avg                   -         (512,)              -               \n","G_mapping/latents_in          -         (?, 512)            -               \n","G_mapping/labels_in           -         (?, 0)              -               \n","G_mapping/Normalize           -         (?, 512)            -               \n","G_mapping/Dense0              262656    (?, 512)            (512, 512)      \n","G_mapping/Dense1              262656    (?, 512)            (512, 512)      \n","G_mapping/Dense2              262656    (?, 512)            (512, 512)      \n","G_mapping/Dense3              262656    (?, 512)            (512, 512)      \n","G_mapping/Dense4              262656    (?, 512)            (512, 512)      \n","G_mapping/Dense5              262656    (?, 512)            (512, 512)      \n","G_mapping/Dense6              262656    (?, 512)            (512, 512)      \n","G_mapping/Dense7              262656    (?, 512)            (512, 512)      \n","G_mapping/Broadcast           -         (?, 16, 512)        -               \n","G_mapping/dlatents_out        -         (?, 16, 512)        -               \n","Truncation/Lerp               -         (?, 16, 512)        -               \n","G_synthesis/dlatents_in       -         (?, 16, 512)        -               \n","G_synthesis/4x4/Const         8192      (?, 512, 4, 4)      (1, 512, 4, 4)  \n","G_synthesis/4x4/Conv          2622465   (?, 512, 4, 4)      (3, 3, 512, 512)\n","G_synthesis/4x4/ToRGB         264195    (?, 3, 4, 4)        (1, 1, 512, 3)  \n","G_synthesis/8x8/Conv0_up      2622465   (?, 512, 8, 8)      (3, 3, 512, 512)\n","G_synthesis/8x8/Conv1         2622465   (?, 512, 8, 8)      (3, 3, 512, 512)\n","G_synthesis/8x8/Upsample      -         (?, 3, 8, 8)        -               \n","G_synthesis/8x8/ToRGB         264195    (?, 3, 8, 8)        (1, 1, 512, 3)  \n","G_synthesis/16x16/Conv0_up    2622465   (?, 512, 16, 16)    (3, 3, 512, 512)\n","G_synthesis/16x16/Conv1       2622465   (?, 512, 16, 16)    (3, 3, 512, 512)\n","G_synthesis/16x16/Upsample    -         (?, 3, 16, 16)      -               \n","G_synthesis/16x16/ToRGB       264195    (?, 3, 16, 16)      (1, 1, 512, 3)  \n","G_synthesis/32x32/Conv0_up    2622465   (?, 512, 32, 32)    (3, 3, 512, 512)\n","G_synthesis/32x32/Conv1       2622465   (?, 512, 32, 32)    (3, 3, 512, 512)\n","G_synthesis/32x32/Upsample    -         (?, 3, 32, 32)      -               \n","G_synthesis/32x32/ToRGB       264195    (?, 3, 32, 32)      (1, 1, 512, 3)  \n","G_synthesis/64x64/Conv0_up    2622465   (?, 512, 64, 64)    (3, 3, 512, 512)\n","G_synthesis/64x64/Conv1       2622465   (?, 512, 64, 64)    (3, 3, 512, 512)\n","G_synthesis/64x64/Upsample    -         (?, 3, 64, 64)      -               \n","G_synthesis/64x64/ToRGB       264195    (?, 3, 64, 64)      (1, 1, 512, 3)  \n","G_synthesis/128x128/Conv0_up  1442561   (?, 256, 128, 128)  (3, 3, 512, 256)\n","G_synthesis/128x128/Conv1     721409    (?, 256, 128, 128)  (3, 3, 256, 256)\n","G_synthesis/128x128/Upsample  -         (?, 3, 128, 128)    -               \n","G_synthesis/128x128/ToRGB     132099    (?, 3, 128, 128)    (1, 1, 256, 3)  \n","G_synthesis/256x256/Conv0_up  426369    (?, 128, 256, 256)  (3, 3, 256, 128)\n","G_synthesis/256x256/Conv1     213249    (?, 128, 256, 256)  (3, 3, 128, 128)\n","G_synthesis/256x256/Upsample  -         (?, 3, 256, 256)    -               \n","G_synthesis/256x256/ToRGB     66051     (?, 3, 256, 256)    (1, 1, 128, 3)  \n","G_synthesis/512x512/Conv0_up  139457    (?, 64, 512, 512)   (3, 3, 128, 64) \n","G_synthesis/512x512/Conv1     69761     (?, 64, 512, 512)   (3, 3, 64, 64)  \n","G_synthesis/512x512/Upsample  -         (?, 3, 512, 512)    -               \n","G_synthesis/512x512/ToRGB     33027     (?, 3, 512, 512)    (1, 1, 64, 3)   \n","G_synthesis/images_out        -         (?, 3, 512, 512)    -               \n","G_synthesis/noise0            -         (1, 1, 4, 4)        -               \n","G_synthesis/noise1            -         (1, 1, 8, 8)        -               \n","G_synthesis/noise2            -         (1, 1, 8, 8)        -               \n","G_synthesis/noise3            -         (1, 1, 16, 16)      -               \n","G_synthesis/noise4            -         (1, 1, 16, 16)      -               \n","G_synthesis/noise5            -         (1, 1, 32, 32)      -               \n","G_synthesis/noise6            -         (1, 1, 32, 32)      -               \n","G_synthesis/noise7            -         (1, 1, 64, 64)      -               \n","G_synthesis/noise8            -         (1, 1, 64, 64)      -               \n","G_synthesis/noise9            -         (1, 1, 128, 128)    -               \n","G_synthesis/noise10           -         (1, 1, 128, 128)    -               \n","G_synthesis/noise11           -         (1, 1, 256, 256)    -               \n","G_synthesis/noise12           -         (1, 1, 256, 256)    -               \n","G_synthesis/noise13           -         (1, 1, 512, 512)    -               \n","G_synthesis/noise14           -         (1, 1, 512, 512)    -               \n","images_out                    -         (?, 3, 512, 512)    -               \n","---                           ---       ---                 ---             \n","Total                         30276583                                      \n","\n","\n","D                    Params    OutputShape         WeightShape     \n","---                  ---       ---                 ---             \n","images_in            -         (?, 3, 512, 512)    -               \n","labels_in            -         (?, 0)              -               \n","512x512/FromRGB      256       (?, 64, 512, 512)   (1, 1, 3, 64)   \n","512x512/Conv0        36928     (?, 64, 512, 512)   (3, 3, 64, 64)  \n","512x512/Conv1_down   73856     (?, 128, 256, 256)  (3, 3, 64, 128) \n","512x512/Skip         8192      (?, 128, 256, 256)  (1, 1, 64, 128) \n","256x256/Conv0        147584    (?, 128, 256, 256)  (3, 3, 128, 128)\n","256x256/Conv1_down   295168    (?, 256, 128, 128)  (3, 3, 128, 256)\n","256x256/Skip         32768     (?, 256, 128, 128)  (1, 1, 128, 256)\n","128x128/Conv0        590080    (?, 256, 128, 128)  (3, 3, 256, 256)\n","128x128/Conv1_down   1180160   (?, 512, 64, 64)    (3, 3, 256, 512)\n","128x128/Skip         131072    (?, 512, 64, 64)    (1, 1, 256, 512)\n","64x64/Conv0          2359808   (?, 512, 64, 64)    (3, 3, 512, 512)\n","64x64/Conv1_down     2359808   (?, 512, 32, 32)    (3, 3, 512, 512)\n","64x64/Skip           262144    (?, 512, 32, 32)    (1, 1, 512, 512)\n","32x32/Conv0          2359808   (?, 512, 32, 32)    (3, 3, 512, 512)\n","32x32/Conv1_down     2359808   (?, 512, 16, 16)    (3, 3, 512, 512)\n","32x32/Skip           262144    (?, 512, 16, 16)    (1, 1, 512, 512)\n","16x16/Conv0          2359808   (?, 512, 16, 16)    (3, 3, 512, 512)\n","16x16/Conv1_down     2359808   (?, 512, 8, 8)      (3, 3, 512, 512)\n","16x16/Skip           262144    (?, 512, 8, 8)      (1, 1, 512, 512)\n","8x8/Conv0            2359808   (?, 512, 8, 8)      (3, 3, 512, 512)\n","8x8/Conv1_down       2359808   (?, 512, 4, 4)      (3, 3, 512, 512)\n","8x8/Skip             262144    (?, 512, 4, 4)      (1, 1, 512, 512)\n","4x4/MinibatchStddev  -         (?, 513, 4, 4)      -               \n","4x4/Conv             2364416   (?, 512, 4, 4)      (3, 3, 513, 512)\n","4x4/Dense0           4194816   (?, 512)            (8192, 512)     \n","Output               513       (?, 1)              (512, 1)        \n","scores_out           -         (?, 1)              -               \n","---                  ---       ---                 ---             \n","Total                28982849                                      \n","\n","Building TensorFlow graph...\n","In shape:\n","(4, 3, 512, 512)\n","Augmenting reals and fake in gpu mode\n","Augment probability 0.2\n","Transposing channels\n","POLICY :  random\n","In shape:\n","(4, 3, 512, 512)\n","Augmenting reals and fake in gpu mode\n","Augment probability 0.2\n","Transposing channels\n","POLICY :  random\n","In shape:\n","(4, 3, 512, 512)\n","Augmenting reals and fake in gpu mode\n","Augment probability 0.2\n","Transposing channels\n","POLICY :  random\n","Initializing logs...\n","Training for 25000 kimg...\n","\n","tick 0     kimg 10000.1  lod 0.00  minibatch 32   time 1m 13s       sec/tick 72.6    sec/kimg 567.25  maintenance 0.0    gpumem 8.4\n","tick 1     kimg 10006.1  lod 0.00  minibatch 32   time 29m 46s      sec/tick 1695.4  sec/kimg 281.82  maintenance 18.1   gpumem 8.4\n","tick 2     kimg 10012.2  lod 0.00  minibatch 32   time 58m 10s      sec/tick 1696.5  sec/kimg 282.00  maintenance 7.7    gpumem 8.4\n","tick 3     kimg 10018.2  lod 0.00  minibatch 32   time 1h 26m 33s   sec/tick 1696.2  sec/kimg 281.94  maintenance 6.1    gpumem 8.4\n","tick 4     kimg 10024.2  lod 0.00  minibatch 32   time 1h 54m 55s   sec/tick 1696.4  sec/kimg 281.99  maintenance 6.1    gpumem 8.4\n","tick 5     kimg 10030.2  lod 0.00  minibatch 32   time 2h 23m 14s   sec/tick 1692.5  sec/kimg 281.33  maintenance 6.3    gpumem 8.4\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pt7jqKQ4wHZe"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"F3fccHsWMXGL"},"source":["# Projection\n","Once the network is trained we can project in selected images.  The first step is to create a dataset file for those images.\n"]},{"cell_type":"code","metadata":{"id":"fiCR5knmMcQ1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614153188179,"user_tz":480,"elapsed":22682,"user":{"displayName":"Casey Rehm","photoUrl":"","userId":"14928713571001354102"}},"outputId":"314a0879-ee5e-4c96-ff56-44dcf0938122"},"source":["!python dataset_tool.py create_from_images_raw /content/drive/MyDrive/stylegan2-aug-colab/stylegan2/datasets/ProjectFiles /content/drive/MyDrive/stylegan2-aug-colab/stylegan2/projectMe"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Loading images from \"/content/drive/MyDrive/stylegan2-aug-colab/stylegan2/projectMe\"\n","detected 45 images ...\n","Shuffle the images...\n","Creating dataset \"/content/drive/MyDrive/stylegan2-aug-colab/stylegan2/datasets/ProjectFiles\"\n","Adding the images to tfrecords ...\n","added images 0\n","Added 45 images.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"3nDUrNJjNp0U"},"source":["Once the new dataset for projection is created you can run this to produce the outputs.\n","\n","\n","1.   set the network flag to the location of your most recent output .pkl\n","2.   check your dataset name and dir\n","\n"]},{"cell_type":"code","metadata":{"id":"g4fd0sT6N0pX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614154610503,"user_tz":480,"elapsed":920381,"user":{"displayName":"Casey Rehm","photoUrl":"","userId":"14928713571001354102"}},"outputId":"ae599dce-7fc1-46af-db23-b7b49d9a00b7"},"source":["!python run_projector.py project-real-images --network=/content/drive/MyDrive/stylegan2-aug-colab/stylegan2/results/00007-stylegan2-Ginza-1gpu-config-f/network-snapshot-010054.pkl --dataset=ProjectFiles --data-dir=/content/drive/MyDrive/stylegan2-aug-colab/stylegan2/datasets --num-images=45"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Local submit - run_dir: results/00010-project-real-images\n","dnnlib: Running run_projector.project_real_images() on localhost...\n","Loading networks from \"/content/drive/MyDrive/stylegan2-aug-colab/stylegan2/results/00007-stylegan2-Ginza-1gpu-config-f/network-snapshot-010054.pkl\"...\n","Setting up TensorFlow plugin \"fused_bias_act.cu\": Preprocessing... Loading... Done.\n","Setting up TensorFlow plugin \"upfirdn_2d.cu\": Preprocessing... Loading... Done.\n","Loading images from \"ProjectFiles\"...\n","Projecting image 0/45 ...\n","Projecting image 1/45 ...\n","Projecting image 2/45 ...\n","Projecting image 3/45 ...\n","Projecting image 4/45 ...\n","Projecting image 5/45 ...\n","Projecting image 6/45 ...\n","Projecting image 7/45 ...\n","Projecting image 8/45 ...\n","Projecting image 9/45 ...\n","Projecting image 10/45 ...\n","Projecting image 11/45 ...\n","Projecting image 12/45 ...\n","Projecting image 13/45 ...\n","Projecting image 14/45 ...\n","Projecting image 15/45 ...\n","Projecting image 16/45 ...\n","Projecting image 17/45 ...\n","Projecting image 18/45 ...\n","Projecting image 19/45 ...\n","Projecting image 20/45 ...\n","Projecting image 21/45 ...\n","Projecting image 22/45 ...\n","Projecting image 23/45 ...\n","Projecting image 24/45 ...\n","Projecting image 25/45 ...\n","Projecting image 26/45 ...\n","Projecting image 27/45 ...\n","Projecting image 28/45 ...\n","Projecting image 29/45 ...\n","Projecting image 30/45 ...\n","Projecting image 31/45 ...\n","Projecting image 32/45 ...\n","Projecting image 33/45 ...\n","Projecting image 34/45 ...\n","Projecting image 35/45 ...\n","Projecting image 36/45 ...\n","Projecting image 37/45 ...\n","Projecting image 38/45 ...\n","Projecting image 39/45 ...\n","Projecting image 40/45 ...\n","Projecting image 41/45 ...\n","Projecting image 42/45 ...\n","Projecting image 43/45 ...\n","Projecting image 44/45 ...\n","dnnlib: Finished run_projector.project_real_images() in 15m 15s.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"u6fhXCgmksF_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615952974686,"user_tz":420,"elapsed":38320,"user":{"displayName":"Casey Rehm","photoUrl":"","userId":"14928713571001354102"}},"outputId":"799466a5-486b-4682-8170-c42b7573d050"},"source":["import numpy as np\r\n","import dnnlib\r\n","import dnnlib.tflib as tflib\r\n","\r\n","import projector\r\n","import pretrained_networks\r\n","from training import dataset\r\n","from training import misc\r\n","import dataset_tool\r\n","import PIL.Image\r\n","import math\r\n","import moviepy.editor\r\n","\r\n","\r\n","def project_image(proj, targets, png_prefix, num_snapshots):\r\n","    snapshot_steps = set(proj.num_steps - np.linspace(0, proj.num_steps, num_snapshots, endpoint=False, dtype=int))    \r\n","    proj.start(targets)\r\n","    while proj.get_cur_step() < proj.num_steps:\r\n","        print('\\r%d / %d ... ' % (proj.get_cur_step(), proj.num_steps), end='', flush=True)\r\n","        proj.step()\r\n","        \r\n","    return proj.get_dlatents()\r\n","    print('\\r%-30s\\r' % '', end='', flush=True)\r\n","\r\n","def project_real_images(Gs,network_pkl, dataset_name, data_dir, num_images, num_snapshots):\r\n","    #print('Loading networks from \"%s\"...' % network_pkl)\r\n","   \r\n","    proj = projector.Projector()\r\n","    proj.set_network(Gs)\r\n","    proj.num_steps = 100\r\n","\r\n","    print('Loading images from \"%s\"...' % dataset_name)\r\n","    dataset_obj = dataset.load_dataset(data_dir=data_dir, tfrecord_dir=dataset_name, max_label_size=0, repeat=False, shuffle_mb=0)\r\n","    assert dataset_obj.shape == Gs.output_shape[1:]\r\n","    dlats = 0\r\n","    for image_idx in range(num_images):\r\n","        print('Projecting image %d/%d ...' % (image_idx, num_images))\r\n","        images, _labels = dataset_obj.get_minibatch_np(1)\r\n","        images = misc.adjust_dynamic_range(images, [0, 255], [-1, 1])\r\n","        dlats = project_image(proj, targets=images, png_prefix=dnnlib.make_run_dir_path('image%04d-' % image_idx), num_snapshots=num_snapshots)\r\n","    return dlats\r\n","\r\n","def main():\r\n","    tflib.init_tf()\r\n","    network_pkl = \"BeastTotal-013891.pkl\"\r\n","    _G, _D, Gs = pretrained_networks.load_networks(network_pkl)\r\n","\r\n","    Gs_kwargs = dnnlib.EasyDict()\r\n","    Gs_kwargs.output_transform = dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True)\r\n","    Gs_kwargs.randomize_noise = False    \r\n","    Gs_kwargs.truncation_psi = .5\r\n","    trunc_psi = .5\r\n","\r\n","    Z_SIZE = Gs.input_shape[1]\r\n","    dataset_tool.create_from_images_raw(\"projection/records/\",\"projection/imgs/\",True)\r\n","    latent1 = project_real_images(Gs,network_pkl,\"records\",\"projection\",1,1)\r\n","    print(latent1)\r\n","    testImg = Gs.components.synthesis.run(latent1, **Gs_kwargs)\r\n","    #output the first image\r\n","    img = PIL.Image.fromarray(testImg[0], 'RGB')\r\n","    img.save(\"test.png\")\r\n","\r\n","    totFrames  = 120\r\n","    step = 24\r\n","    latentList = []\r\n","    \r\n","    for i in range(5):\r\n","        #temporary latent vector\r\n","        latent2 = Gs.Components.mapping.RUN(np.random.rand(1,Z_SIZE), None, truncation_psi=trunc_psi)\r\n","        latentList.append(latent2)\r\n","    \r\n","    curPos = 0\r\n","    curLatent = 0\r\n","    frame_List = []\r\n","\r\n","    for i in range(totFrames):\r\n","        print(\"frame\" + i)\r\n","        factor = curPos/(step)\r\n","        facotr = math.cos(2*factor*math.pi)*.5+.5\r\n","        current_latent = latentList[curLatent]*(1-factor) + latent1*factor\r\n","        #output the first image\r\n","        current_image = Gs.components.synthesis.run(current_latent, **Gs_kwargs)[0]\r\n","        frame_List.append(current_image)\r\n","        curPos = curPos+1\r\n","        if curPos == step:\r\n","            curPos = 0\r\n","            curLatent+=1\r\n","\r\n","    mp4_file = 'bounce.mp4'\r\n","    mp4_codec = 'libx264'\r\n","    mp4_bitrate = '3M'\r\n","    mp4_fps = step\r\n","\r\n","    frames = moviepy.editor.ImageSequenceClip(frame_List, fps = mp4_fps)\r\n","    frames.write_videofile(mp4_file, fps = mp4_fps, codec = mp4_codec, bitrate = mp4_bitrate)\r\n","\r\n","\r\n","if __name__ == \"__main__\":\r\n","    main()\r\n","\r\n","\r\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Loading images from \"projection/imgs/\"\n","detected 1 images ...\n","Shuffle the images...\n","Creating dataset \"projection/records/\"\n","Adding the images to tfrecords ...\n","added images 0\n","Added 1 images.\n","Loading images from \"records\"...\n","Projecting image 0/1 ...\n","99 / 100 ... [[[-1.8190513 -0.7479352  1.7075641 ...  1.4721916  1.572751   2.32079  ]\n","  [-1.8190513 -0.7479352  1.7075641 ...  1.4721916  1.572751   2.32079  ]\n","  [-1.8190513 -0.7479352  1.7075641 ...  1.4721916  1.572751   2.32079  ]\n","  ...\n","  [-1.8190513 -0.7479352  1.7075641 ...  1.4721916  1.572751   2.32079  ]\n","  [-1.8190513 -0.7479352  1.7075641 ...  1.4721916  1.572751   2.32079  ]\n","  [-1.8190513 -0.7479352  1.7075641 ...  1.4721916  1.572751   2.32079  ]]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"MIAN2b-FP6I4"},"source":["# RandomImage Generation and Interpolation"]},{"cell_type":"code","metadata":{"id":"ExDOud8RYO6b","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615950806059,"user_tz":420,"elapsed":308,"user":{"displayName":"Casey Rehm","photoUrl":"","userId":"14928713571001354102"}},"outputId":"53b4b00a-b233-4cc0-b8a1-389d05a6be19"},"source":["%cd /content/drive/MyDrive/stylegan2-aug-colab/stylegan2"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/stylegan2-aug-colab/stylegan2\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"J-DT1F9eXAEo"},"source":["This code will create a sequence of png's smoothly blending between random points in the network.   \n","\n","1.   Change line 41 to your network\n","2.   Change Tokyo to your image name on line 83\n","\n"]},{"cell_type":"code","metadata":{"id":"1Sgpu8xQQC5u","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615940038400,"user_tz":420,"elapsed":8262918,"user":{"displayName":"Casey Rehm","photoUrl":"","userId":"14928713571001354102"}},"outputId":"0dea5f35-082e-481a-eed8-72ea2588f15c"},"source":["# Copyright (c) 2019, NVIDIA Corporation. All rights reserved.\n","#\n","# This work is made available under the Nvidia Source Code License-NC.\n","# To view a copy of this license, visit\n","# https://nvlabs.github.io/stylegan2/license.html\n","\n","import argparse\n","import numpy as np\n","import PIL.Image\n","import dnnlib\n","import dnnlib.tflib as tflib\n","\n","\n","import pretrained_networks\n","\n","#----------------------------------------------------------------------------\n","def create_image_grid(images, grid_size=None):\n","    assert images.ndim == 3 or images.ndim == 4\n","    num, img_h, img_w, channels = images.shape\n","\n","    if grid_size is not None:\n","        grid_w, grid_h = tuple(grid_size)\n","    else:\n","        grid_w = max(int(np.ceil(np.sqrt(num))), 1)\n","        grid_h = max((num - 1) // grid_w + 1, 1)\n","\n","    grid = np.zeros([grid_h * img_h, grid_w * img_w, channels], dtype=images.dtype)\n","    for idx in range(num):\n","        x = (idx % grid_w) * img_w\n","        y = (idx // grid_w) * img_h\n","        grid[y: y + img_h, x: x + img_w] = images[idx]\n","    return grid\n","\n","def genGrid():\n","\n","    tflib.init_tf()\n","\n","    # Load pre-trained network.\n","\n","    ## NOTE: insert model here:\n","    _G, _D, Gs = pretrained_networks.load_networks(\"CLDSpace-010030.pkl\")\n","\n","\n","    grid_size = [8,5]\n","\n","    image_zoom = 1\n","    duration_sec = 60\n","    smoothing_sec = .5\n","    mp4_fps = 24\n","    random_seed = 8004\n","    minibatch_size = 8\n","    cnt = 0\n","    num_frames = int(np.rint(duration_sec * mp4_fps))\n","    random_state = np.random.RandomState(random_seed)\n","\n","    # Generate latent vectors\n","    shape = [num_frames, np.prod(grid_size)] + Gs.input_shape[1:] # [frame, image, channel, component]\n","    all_latents = random_state.randn(*shape).astype(np.float32)\n","    import scipy\n","    all_latents = scipy.ndimage.gaussian_filter(all_latents, [smoothing_sec * mp4_fps] + [0] * len(Gs.input_shape), mode='wrap')\n","    all_latents /= np.sqrt(np.mean(np.square(all_latents)))\n","\n","\n","    # Frame generation func for moviepy.\n","    for t in range(num_frames):\n","        v = t/24\n","        frame_idx = int(np.clip(np.round(v * mp4_fps), 0, num_frames - 1))\n","        latents = all_latents[frame_idx]\n","        fmt = dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True)\n","        images = Gs.run(latents, None, truncation_psi=0.75,\n","                              randomize_noise=False, output_transform=fmt)\n","\n","        grid = create_image_grid(images, grid_size)\n","        if image_zoom > 1:\n","            grid = scipy.ndimage.zoom(grid, [image_zoom, image_zoom, 1], order=0)\n","        if grid.shape[2] == 1:\n","            grid = grid.repeat(3, 2) # grayscale => RGB\n","        canvas = PIL.Image.fromarray(grid)\n","        cnt = t\n","        #cnt = int(t*24)\n","        cnt = \"{:04d}\".format(cnt)\n","        print(cnt)\n","        fName = 'CLDSpaceImages/CLDSpace_' + str(cnt) + '.png'\n","\n","\n","        canvas.save(fName)\n","        #return grid\n","\n","\n","\n","\n","def main():\n","   genGrid()\n","\n","#----------------------------------------------------------------------------\n","\n","if __name__ == \"__main__\":\n","    main()\n","\n","#----------------------------------------------------------------------------\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Setting up TensorFlow plugin \"fused_bias_act.cu\": Preprocessing... Loading... Done.\n","Setting up TensorFlow plugin \"upfirdn_2d.cu\": Preprocessing... Loading... Done.\n","0000\n","0001\n","0002\n","0003\n","0004\n","0005\n","0006\n","0007\n","0008\n","0009\n","0010\n","0011\n","0012\n","0013\n","0014\n","0015\n","0016\n","0017\n","0018\n","0019\n","0020\n","0021\n","0022\n","0023\n","0024\n","0025\n","0026\n","0027\n","0028\n","0029\n","0030\n","0031\n","0032\n","0033\n","0034\n","0035\n","0036\n","0037\n","0038\n","0039\n","0040\n","0041\n","0042\n","0043\n","0044\n","0045\n","0046\n","0047\n","0048\n","0049\n","0050\n","0051\n","0052\n","0053\n","0054\n","0055\n","0056\n","0057\n","0058\n","0059\n","0060\n","0061\n","0062\n","0063\n","0064\n","0065\n","0066\n","0067\n","0068\n","0069\n","0070\n","0071\n","0072\n","0073\n","0074\n","0075\n","0076\n","0077\n","0078\n","0079\n","0080\n","0081\n","0082\n","0083\n","0084\n","0085\n","0086\n","0087\n","0088\n","0089\n","0090\n","0091\n","0092\n","0093\n","0094\n","0095\n","0096\n","0097\n","0098\n","0099\n","0100\n","0101\n","0102\n","0103\n","0104\n","0105\n","0106\n","0107\n","0108\n","0109\n","0110\n","0111\n","0112\n","0113\n","0114\n","0115\n","0116\n","0117\n","0118\n","0119\n","0120\n","0121\n","0122\n","0123\n","0124\n","0125\n","0126\n","0127\n","0128\n","0129\n","0130\n","0131\n","0132\n","0133\n","0134\n","0135\n","0136\n","0137\n","0138\n","0139\n","0140\n","0141\n","0142\n","0143\n","0144\n","0145\n","0146\n","0147\n","0148\n","0149\n","0150\n","0151\n","0152\n","0153\n","0154\n","0155\n","0156\n","0157\n","0158\n","0159\n","0160\n","0161\n","0162\n","0163\n","0164\n","0165\n","0166\n","0167\n","0168\n","0169\n","0170\n","0171\n","0172\n","0173\n","0174\n","0175\n","0176\n","0177\n","0178\n","0179\n","0180\n","0181\n","0182\n","0183\n","0184\n","0185\n","0186\n","0187\n","0188\n","0189\n","0190\n","0191\n","0192\n","0193\n","0194\n","0195\n","0196\n","0197\n","0198\n","0199\n","0200\n","0201\n","0202\n","0203\n","0204\n","0205\n","0206\n","0207\n","0208\n","0209\n","0210\n","0211\n","0212\n","0213\n","0214\n","0215\n","0216\n","0217\n","0218\n","0219\n","0220\n","0221\n","0222\n","0223\n","0224\n","0225\n","0226\n","0227\n","0228\n","0229\n","0230\n","0231\n","0232\n","0233\n","0234\n","0235\n","0236\n","0237\n","0238\n","0239\n","0240\n","0241\n","0242\n","0243\n","0244\n","0245\n","0246\n","0247\n","0248\n","0249\n","0250\n","0251\n","0252\n","0253\n","0254\n","0255\n","0256\n","0257\n","0258\n","0259\n","0260\n","0261\n","0262\n","0263\n","0264\n","0265\n","0266\n","0267\n","0268\n","0269\n","0270\n","0271\n","0272\n","0273\n","0274\n","0275\n","0276\n","0277\n","0278\n","0279\n","0280\n","0281\n","0282\n","0283\n","0284\n","0285\n","0286\n","0287\n","0288\n","0289\n","0290\n","0291\n","0292\n","0293\n","0294\n","0295\n","0296\n","0297\n","0298\n","0299\n","0300\n","0301\n","0302\n","0303\n","0304\n","0305\n","0306\n","0307\n","0308\n","0309\n","0310\n","0311\n","0312\n","0313\n","0314\n","0315\n","0316\n","0317\n","0318\n","0319\n","0320\n","0321\n","0322\n","0323\n","0324\n","0325\n","0326\n","0327\n","0328\n","0329\n","0330\n","0331\n","0332\n","0333\n","0334\n","0335\n","0336\n","0337\n","0338\n","0339\n","0340\n","0341\n","0342\n","0343\n","0344\n","0345\n","0346\n","0347\n","0348\n","0349\n","0350\n","0351\n","0352\n","0353\n","0354\n","0355\n","0356\n","0357\n","0358\n","0359\n","0360\n","0361\n","0362\n","0363\n","0364\n","0365\n","0366\n","0367\n","0368\n","0369\n","0370\n","0371\n","0372\n","0373\n","0374\n","0375\n","0376\n","0377\n","0378\n","0379\n","0380\n","0381\n","0382\n","0383\n","0384\n","0385\n","0386\n","0387\n","0388\n","0389\n","0390\n","0391\n","0392\n","0393\n","0394\n","0395\n","0396\n","0397\n","0398\n","0399\n","0400\n","0401\n","0402\n","0403\n","0404\n","0405\n","0406\n","0407\n","0408\n","0409\n","0410\n","0411\n","0412\n","0413\n","0414\n","0415\n","0416\n","0417\n","0418\n","0419\n","0420\n","0421\n","0422\n","0423\n","0424\n","0425\n","0426\n","0427\n","0428\n","0429\n","0430\n","0431\n","0432\n","0433\n","0434\n","0435\n","0436\n","0437\n","0438\n","0439\n","0440\n","0441\n","0442\n","0443\n","0444\n","0445\n","0446\n","0447\n","0448\n","0449\n","0450\n","0451\n","0452\n","0453\n","0454\n","0455\n","0456\n","0457\n","0458\n","0459\n","0460\n","0461\n","0462\n","0463\n","0464\n","0465\n","0466\n","0467\n","0468\n","0469\n","0470\n","0471\n","0472\n","0473\n","0474\n","0475\n","0476\n","0477\n","0478\n","0479\n","0480\n","0481\n","0482\n","0483\n","0484\n","0485\n","0486\n","0487\n","0488\n","0489\n","0490\n","0491\n","0492\n","0493\n","0494\n","0495\n","0496\n","0497\n","0498\n","0499\n","0500\n","0501\n","0502\n","0503\n","0504\n","0505\n","0506\n","0507\n","0508\n","0509\n","0510\n","0511\n","0512\n","0513\n","0514\n","0515\n","0516\n","0517\n","0518\n","0519\n","0520\n","0521\n","0522\n","0523\n","0524\n","0525\n","0526\n","0527\n","0528\n","0529\n","0530\n","0531\n","0532\n","0533\n","0534\n","0535\n","0536\n","0537\n","0538\n","0539\n","0540\n","0541\n","0542\n","0543\n","0544\n","0545\n","0546\n","0547\n","0548\n","0549\n","0550\n","0551\n","0552\n","0553\n","0554\n","0555\n","0556\n","0557\n","0558\n","0559\n","0560\n","0561\n","0562\n","0563\n","0564\n","0565\n","0566\n","0567\n","0568\n","0569\n","0570\n","0571\n","0572\n","0573\n","0574\n","0575\n","0576\n","0577\n","0578\n","0579\n","0580\n","0581\n","0582\n","0583\n","0584\n","0585\n","0586\n","0587\n","0588\n","0589\n","0590\n","0591\n","0592\n","0593\n","0594\n","0595\n","0596\n","0597\n","0598\n","0599\n","0600\n","0601\n","0602\n","0603\n","0604\n","0605\n","0606\n","0607\n","0608\n","0609\n","0610\n","0611\n","0612\n","0613\n","0614\n","0615\n","0616\n","0617\n","0618\n","0619\n","0620\n","0621\n","0622\n","0623\n","0624\n","0625\n","0626\n","0627\n","0628\n","0629\n","0630\n","0631\n","0632\n","0633\n","0634\n","0635\n","0636\n","0637\n","0638\n","0639\n","0640\n","0641\n","0642\n","0643\n","0644\n","0645\n","0646\n","0647\n","0648\n","0649\n","0650\n","0651\n","0652\n","0653\n","0654\n","0655\n","0656\n","0657\n","0658\n","0659\n","0660\n","0661\n","0662\n","0663\n","0664\n","0665\n","0666\n","0667\n","0668\n","0669\n","0670\n","0671\n","0672\n","0673\n","0674\n","0675\n","0676\n","0677\n","0678\n","0679\n","0680\n","0681\n","0682\n","0683\n","0684\n","0685\n","0686\n","0687\n","0688\n","0689\n","0690\n","0691\n","0692\n","0693\n","0694\n","0695\n","0696\n","0697\n","0698\n","0699\n","0700\n","0701\n","0702\n","0703\n","0704\n","0705\n","0706\n","0707\n","0708\n","0709\n","0710\n","0711\n","0712\n","0713\n","0714\n","0715\n","0716\n","0717\n","0718\n","0719\n","0720\n","0721\n","0722\n","0723\n","0724\n","0725\n","0726\n","0727\n","0728\n","0729\n","0730\n","0731\n","0732\n","0733\n","0734\n","0735\n","0736\n","0737\n","0738\n","0739\n","0740\n","0741\n","0742\n","0743\n","0744\n","0745\n","0746\n","0747\n","0748\n","0749\n","0750\n","0751\n","0752\n","0753\n","0754\n","0755\n","0756\n","0757\n","0758\n","0759\n","0760\n","0761\n","0762\n","0763\n","0764\n","0765\n","0766\n","0767\n","0768\n","0769\n","0770\n","0771\n","0772\n","0773\n","0774\n","0775\n","0776\n","0777\n","0778\n","0779\n","0780\n","0781\n","0782\n","0783\n","0784\n","0785\n","0786\n","0787\n","0788\n","0789\n","0790\n","0791\n","0792\n","0793\n","0794\n","0795\n","0796\n","0797\n","0798\n","0799\n","0800\n","0801\n","0802\n","0803\n","0804\n","0805\n","0806\n","0807\n","0808\n","0809\n","0810\n","0811\n","0812\n","0813\n","0814\n","0815\n","0816\n","0817\n","0818\n","0819\n","0820\n","0821\n","0822\n","0823\n","0824\n","0825\n","0826\n","0827\n","0828\n","0829\n","0830\n","0831\n","0832\n","0833\n","0834\n","0835\n","0836\n","0837\n","0838\n","0839\n","0840\n","0841\n","0842\n","0843\n","0844\n","0845\n","0846\n","0847\n","0848\n","0849\n","0850\n","0851\n","0852\n","0853\n","0854\n","0855\n","0856\n","0857\n","0858\n","0859\n","0860\n","0861\n","0862\n","0863\n","0864\n","0865\n","0866\n","0867\n","0868\n","0869\n","0870\n","0871\n","0872\n","0873\n","0874\n","0875\n","0876\n","0877\n","0878\n","0879\n","0880\n","0881\n","0882\n","0883\n","0884\n","0885\n","0886\n","0887\n","0888\n","0889\n","0890\n","0891\n","0892\n","0893\n","0894\n","0895\n","0896\n","0897\n","0898\n","0899\n","0900\n","0901\n","0902\n","0903\n","0904\n","0905\n","0906\n","0907\n","0908\n","0909\n","0910\n","0911\n","0912\n","0913\n","0914\n","0915\n","0916\n","0917\n","0918\n","0919\n","0920\n","0921\n","0922\n","0923\n","0924\n","0925\n","0926\n","0927\n","0928\n","0929\n","0930\n","0931\n","0932\n","0933\n","0934\n","0935\n","0936\n","0937\n","0938\n","0939\n","0940\n","0941\n","0942\n","0943\n","0944\n","0945\n","0946\n","0947\n","0948\n","0949\n","0950\n","0951\n","0952\n","0953\n","0954\n","0955\n","0956\n","0957\n","0958\n","0959\n","0960\n","0961\n","0962\n","0963\n","0964\n","0965\n","0966\n","0967\n","0968\n","0969\n","0970\n","0971\n","0972\n","0973\n","0974\n","0975\n","0976\n","0977\n","0978\n","0979\n","0980\n","0981\n","0982\n","0983\n","0984\n","0985\n","0986\n","0987\n","0988\n","0989\n","0990\n","0991\n","0992\n","0993\n","0994\n","0995\n","0996\n","0997\n","0998\n","0999\n","1000\n","1001\n","1002\n","1003\n","1004\n","1005\n","1006\n","1007\n","1008\n","1009\n","1010\n","1011\n","1012\n","1013\n","1014\n","1015\n","1016\n","1017\n","1018\n","1019\n","1020\n","1021\n","1022\n","1023\n","1024\n","1025\n","1026\n","1027\n","1028\n","1029\n","1030\n","1031\n","1032\n","1033\n","1034\n","1035\n","1036\n","1037\n","1038\n","1039\n","1040\n","1041\n","1042\n","1043\n","1044\n","1045\n","1046\n","1047\n","1048\n","1049\n","1050\n","1051\n","1052\n","1053\n","1054\n","1055\n","1056\n","1057\n","1058\n","1059\n","1060\n","1061\n","1062\n","1063\n","1064\n","1065\n","1066\n","1067\n","1068\n","1069\n","1070\n","1071\n","1072\n","1073\n","1074\n","1075\n","1076\n","1077\n","1078\n","1079\n","1080\n","1081\n","1082\n","1083\n","1084\n","1085\n","1086\n","1087\n","1088\n","1089\n","1090\n","1091\n","1092\n","1093\n","1094\n","1095\n","1096\n","1097\n","1098\n","1099\n","1100\n","1101\n","1102\n","1103\n","1104\n","1105\n","1106\n","1107\n","1108\n","1109\n","1110\n","1111\n","1112\n","1113\n","1114\n","1115\n","1116\n","1117\n","1118\n","1119\n","1120\n","1121\n","1122\n","1123\n","1124\n","1125\n","1126\n","1127\n","1128\n","1129\n","1130\n","1131\n","1132\n","1133\n","1134\n","1135\n","1136\n","1137\n","1138\n","1139\n","1140\n","1141\n","1142\n","1143\n","1144\n","1145\n","1146\n","1147\n","1148\n","1149\n","1150\n","1151\n","1152\n","1153\n","1154\n","1155\n","1156\n","1157\n","1158\n","1159\n","1160\n","1161\n","1162\n","1163\n","1164\n","1165\n","1166\n","1167\n","1168\n","1169\n","1170\n","1171\n","1172\n","1173\n","1174\n","1175\n","1176\n","1177\n","1178\n","1179\n","1180\n","1181\n","1182\n","1183\n","1184\n","1185\n","1186\n","1187\n","1188\n","1189\n","1190\n","1191\n","1192\n","1193\n","1194\n","1195\n","1196\n","1197\n","1198\n","1199\n","1200\n","1201\n","1202\n","1203\n","1204\n","1205\n","1206\n","1207\n","1208\n","1209\n","1210\n","1211\n","1212\n","1213\n","1214\n","1215\n","1216\n","1217\n","1218\n","1219\n","1220\n","1221\n","1222\n","1223\n","1224\n","1225\n","1226\n","1227\n","1228\n","1229\n","1230\n","1231\n","1232\n","1233\n","1234\n","1235\n","1236\n","1237\n","1238\n","1239\n","1240\n","1241\n","1242\n","1243\n","1244\n","1245\n","1246\n","1247\n","1248\n","1249\n","1250\n","1251\n","1252\n","1253\n","1254\n","1255\n","1256\n","1257\n","1258\n","1259\n","1260\n","1261\n","1262\n","1263\n","1264\n","1265\n","1266\n","1267\n","1268\n","1269\n","1270\n","1271\n","1272\n","1273\n","1274\n","1275\n","1276\n","1277\n","1278\n","1279\n","1280\n","1281\n","1282\n","1283\n","1284\n","1285\n","1286\n","1287\n","1288\n","1289\n","1290\n","1291\n","1292\n","1293\n","1294\n","1295\n","1296\n","1297\n","1298\n","1299\n","1300\n","1301\n","1302\n","1303\n","1304\n","1305\n","1306\n","1307\n","1308\n","1309\n","1310\n","1311\n","1312\n","1313\n","1314\n","1315\n","1316\n","1317\n","1318\n","1319\n","1320\n","1321\n","1322\n","1323\n","1324\n","1325\n","1326\n","1327\n","1328\n","1329\n","1330\n","1331\n","1332\n","1333\n","1334\n","1335\n","1336\n","1337\n","1338\n","1339\n","1340\n","1341\n","1342\n","1343\n","1344\n","1345\n","1346\n","1347\n","1348\n","1349\n","1350\n","1351\n","1352\n","1353\n","1354\n","1355\n","1356\n","1357\n","1358\n","1359\n","1360\n","1361\n","1362\n","1363\n","1364\n","1365\n","1366\n","1367\n","1368\n","1369\n","1370\n","1371\n","1372\n","1373\n","1374\n","1375\n","1376\n","1377\n","1378\n","1379\n","1380\n","1381\n","1382\n","1383\n","1384\n","1385\n","1386\n","1387\n","1388\n","1389\n","1390\n","1391\n","1392\n","1393\n","1394\n","1395\n","1396\n","1397\n","1398\n","1399\n","1400\n","1401\n","1402\n","1403\n","1404\n","1405\n","1406\n","1407\n","1408\n","1409\n","1410\n","1411\n","1412\n","1413\n","1414\n","1415\n","1416\n","1417\n","1418\n","1419\n","1420\n","1421\n","1422\n","1423\n","1424\n","1425\n","1426\n","1427\n","1428\n","1429\n","1430\n","1431\n","1432\n","1433\n","1434\n","1435\n","1436\n","1437\n","1438\n","1439\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lPSR0OGvZo9Q"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4TiDbmc21Yuw"},"source":["# **StyleMixing Grid Production**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LBV0WZ0b1db3","executionInfo":{"status":"ok","timestamp":1615263692456,"user_tz":480,"elapsed":51730,"user":{"displayName":"Casey Rehm","photoUrl":"","userId":"14928713571001354102"}},"outputId":"b298bed2-d6b6-49bf-9645-a1e6db65450c"},"source":["# Copyright (c) 2019, NVIDIA CORPORATION. All rights reserved.\r\n","#\r\n","# This work is licensed under the Creative Commons Attribution-NonCommercial\r\n","# 4.0 International License. To view a copy of this license, visit\r\n","# http://creativecommons.org/licenses/by-nc/4.0/ or send a letter to\r\n","# Creative Commons, PO Box 1866, Mountain View, CA 94042, USA.\r\n","\r\n","\"\"\"Minimal script for reproducing the figures of the StyleGAN paper using pre-trained generators.\"\"\"\r\n","\r\n","import os\r\n","import pickle\r\n","import numpy as np\r\n","import PIL.Image\r\n","import dnnlib\r\n","import dnnlib.tflib as tflib\r\n","\r\n","\r\n","#----------------------------------------------------------------------------\r\n","# Helpers for loading and using pre-trained generators.\r\n","\r\n","\r\n","\r\n","synthesis_kwargs = dict(output_transform=dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True), minibatch_size=8)\r\n","\r\n","_Gs_cache = dict()\r\n","\r\n","# def load_Gs(url):\r\n","#     if url not in _Gs_cache:\r\n","#         with dnnlib.util.open_url(url, cache_dir=config.cache_dir) as f:\r\n","#             _G, _D, Gs = pickle.load(f)\r\n","#         _Gs_cache[url] = Gs\r\n","#     return _Gs_cache[url]\r\n","def load_Gs():\r\n","    _G, _D, Gs = pickle.load(open(\"BeastTotal-013891.pkl\",\"rb\"))\r\n","    return Gs\r\n","#----------------------------------------------------------------------------\r\n","# Figures 2, 3, 10, 11, 12: Multi-resolution grid of uncurated result images.\r\n","\r\n","def draw_uncurated_result_figure(png, Gs, cx, cy, cw, ch, rows, lods, seed):\r\n","    print(png)\r\n","    latents = np.random.RandomState(seed).randn(sum(rows * 2**lod for lod in lods), Gs.input_shape[1])\r\n","    images = Gs.run(latents, None, **synthesis_kwargs) # [seed, y, x, rgb]\r\n","\r\n","    canvas = PIL.Image.new('RGB', (sum(cw // 2**lod for lod in lods), ch * rows), 'white')\r\n","    image_iter = iter(list(images))\r\n","    for col, lod in enumerate(lods):\r\n","        for row in range(rows * 2**lod):\r\n","            image = PIL.Image.fromarray(next(image_iter), 'RGB')\r\n","            image = image.crop((cx, cy, cx + cw, cy + ch))\r\n","            image = image.resize((cw // 2**lod, ch // 2**lod), PIL.Image.ANTIALIAS)\r\n","            canvas.paste(image, (sum(cw // 2**lod for lod in lods[:col]), row * ch // 2**lod))\r\n","    canvas.save(png)\r\n","\r\n","#----------------------------------------------------------------------------\r\n","# Figure 3: Style mixing.\r\n","\r\n","def draw_style_mixing_figure(png, Gs, w, h, src_seeds, dst_seeds, style_ranges):\r\n","    print(png)\r\n","    src_latents = np.stack(np.random.RandomState(seed).randn(Gs.input_shape[1]) for seed in src_seeds)\r\n","    dst_latents = np.stack(np.random.RandomState(seed).randn(Gs.input_shape[1]) for seed in dst_seeds)\r\n","    src_dlatents = Gs.components.mapping.run(src_latents, None) # [seed, layer, component]\r\n","    dst_dlatents = Gs.components.mapping.run(dst_latents, None) # [seed, layer, component]\r\n","    src_images = Gs.components.synthesis.run(src_dlatents, randomize_noise=False, **synthesis_kwargs)\r\n","    dst_images = Gs.components.synthesis.run(dst_dlatents, randomize_noise=False, **synthesis_kwargs)\r\n","\r\n","    canvas = PIL.Image.new('RGB', (w * (len(src_seeds) + 1), h * (len(dst_seeds) + 1)), 'white')\r\n","    for col, src_image in enumerate(list(src_images)):\r\n","        canvas.paste(PIL.Image.fromarray(src_image, 'RGB'), ((col + 1) * w, 0))\r\n","    for row, dst_image in enumerate(list(dst_images)):\r\n","        canvas.paste(PIL.Image.fromarray(dst_image, 'RGB'), (0, (row + 1) * h))\r\n","        row_dlatents = np.stack([dst_dlatents[row]] * len(src_seeds))\r\n","        row_dlatents[:, style_ranges[row]] = src_dlatents[:, style_ranges[row]]\r\n","        row_images = Gs.components.synthesis.run(row_dlatents, randomize_noise=False, **synthesis_kwargs)\r\n","        for col, image in enumerate(list(row_images)):\r\n","            canvas.paste(PIL.Image.fromarray(image, 'RGB'), ((col + 1) * w, (row + 1) * h))\r\n","    canvas.save(png)\r\n","\r\n","#----------------------------------------------------------------------------\r\n","# Figure 4: Noise detail.\r\n","\r\n","def draw_noise_detail_figure(png, Gs, w, h, num_samples, seeds):\r\n","    print(png)\r\n","    canvas = PIL.Image.new('RGB', (w * 3, h * len(seeds)), 'white')\r\n","    for row, seed in enumerate(seeds):\r\n","        latents = np.stack([np.random.RandomState(seed).randn(Gs.input_shape[1])] * num_samples)\r\n","        images = Gs.run(latents, None, truncation_psi=1, **synthesis_kwargs)\r\n","        canvas.paste(PIL.Image.fromarray(images[0], 'RGB'), (0, row * h))\r\n","        for i in range(4):\r\n","            crop = PIL.Image.fromarray(images[i + 1], 'RGB')\r\n","            crop = crop.crop((650, 180, 906, 436))\r\n","            crop = crop.resize((w//2, h//2), PIL.Image.NEAREST)\r\n","            canvas.paste(crop, (w + (i%2) * w//2, row * h + (i//2) * h//2))\r\n","        diff = np.std(np.mean(images, axis=3), axis=0) * 4\r\n","        diff = np.clip(diff + 0.5, 0, 255).astype(np.uint8)\r\n","        canvas.paste(PIL.Image.fromarray(diff, 'L'), (w * 2, row * h))\r\n","    canvas.save(png)\r\n","\r\n","#----------------------------------------------------------------------------\r\n","# Figure 5: Noise components.\r\n","\r\n","def draw_noise_components_figure(png, Gs, w, h, seeds, noise_ranges, flips):\r\n","    print(png)\r\n","    Gsc = Gs.clone()\r\n","    noise_vars = [var for name, var in Gsc.components.synthesis.vars.items() if name.startswith('noise')]\r\n","    noise_pairs = list(zip(noise_vars, tflib.run(noise_vars))) # [(var, val), ...]\r\n","    latents = np.stack(np.random.RandomState(seed).randn(Gs.input_shape[1]) for seed in seeds)\r\n","    all_images = []\r\n","    for noise_range in noise_ranges:\r\n","        tflib.set_vars({var: val * (1 if i in noise_range else 0) for i, (var, val) in enumerate(noise_pairs)})\r\n","        range_images = Gsc.run(latents, None, truncation_psi=1, randomize_noise=False, **synthesis_kwargs)\r\n","        range_images[flips, :, :] = range_images[flips, :, ::-1]\r\n","        all_images.append(list(range_images))\r\n","\r\n","    canvas = PIL.Image.new('RGB', (w * 2, h * 2), 'white')\r\n","    for col, col_images in enumerate(zip(*all_images)):\r\n","        canvas.paste(PIL.Image.fromarray(col_images[0], 'RGB').crop((0, 0, w//2, h)), (col * w, 0))\r\n","        canvas.paste(PIL.Image.fromarray(col_images[1], 'RGB').crop((w//2, 0, w, h)), (col * w + w//2, 0))\r\n","        canvas.paste(PIL.Image.fromarray(col_images[2], 'RGB').crop((0, 0, w//2, h)), (col * w, h))\r\n","        canvas.paste(PIL.Image.fromarray(col_images[3], 'RGB').crop((w//2, 0, w, h)), (col * w + w//2, h))\r\n","    canvas.save(png)\r\n","\r\n","#----------------------------------------------------------------------------\r\n","# Figure 8: Truncation trick.\r\n","\r\n","def draw_truncation_trick_figure(png, Gs, w, h, seeds, psis):\r\n","    print(png)\r\n","    latents = np.stack(np.random.RandomState(seed).randn(Gs.input_shape[1]) for seed in seeds)\r\n","    dlatents = Gs.components.mapping.run(latents, None) # [seed, layer, component]\r\n","    dlatent_avg = Gs.get_var('dlatent_avg') # [component]\r\n","\r\n","    canvas = PIL.Image.new('RGB', (w * len(psis), h * len(seeds)), 'white')\r\n","    for row, dlatent in enumerate(list(dlatents)):\r\n","        row_dlatents = (dlatent[np.newaxis] - dlatent_avg) * np.reshape(psis, [-1, 1, 1]) + dlatent_avg\r\n","        row_images = Gs.components.synthesis.run(row_dlatents, randomize_noise=False, **synthesis_kwargs)\r\n","        for col, image in enumerate(list(row_images)):\r\n","            canvas.paste(PIL.Image.fromarray(image, 'RGB'), (col * w, row * h))\r\n","    canvas.save(png)\r\n","\r\n","#----------------------------------------------------------------------------\r\n","# Main program.\r\n","\r\n","def main():\r\n","    tflib.init_tf()\r\n","    DIR = \"StyleMix\"\r\n","    os.makedirs(DIR, exist_ok=True)\r\n","\r\n","    startSeed = 800\r\n","    startDis = 200\r\n","    startPsi = 1\r\n","    quant = 16\r\n","    seedList = []\r\n","\r\n","    distList = []\r\n","    psiList = []\r\n","\r\n","    dimStep = 2/quant\r\n","\r\n","\r\n","    for i in range(quant):\r\n","        tempSeed = startSeed+ i\r\n","        tempDis = startDis +i\r\n","        seedList.append(tempSeed)\r\n","        if(i > 0):\r\n","            distList.append(tempDis)\r\n","        if(i%2 == 0):\r\n","            tempPsi = startPsi - (i * dimStep)\r\n","            psiList.append(tempPsi)\r\n","\r\n","    \r\n","    draw_style_mixing_figure(os.path.join(DIR, 'BeastMix2.png'), load_Gs(), w=512, h=512, src_seeds=distList, dst_seeds=seedList, style_ranges=[range(0,4)]*16+[range(4,8)]*15+[range(8,16)])\r\n","    \r\n","\r\n","#----------------------------------------------------------------------------\r\n","\r\n","if __name__ == \"__main__\":\r\n","    main()\r\n","\r\n","#----------------------------------------------------------------------------\r\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["StyleMix/BeastMix2.png\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:176: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"at1uqr6hLf5Q"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NE46C1mZOX3n"},"source":["Quick Linear Interpolation"]},{"cell_type":"code","metadata":{"id":"SnH4lFXBOWt4"},"source":["import os\r\n","import pickle\r\n","import numpy as np\r\n","import PIL.Image\r\n","import dnnlib\r\n","import dnnlib.tflib as tflib\r\n","\r\n","\r\n","def main():\r\n","    DIR = \"Blend\"\r\n","    os.makedirs(DIR, exist_ok=True)\r\n","    network_pkl = \"BeastTotal-013891.pkl\"\r\n","    _G, _D, Gs = pretrained_networks.load_networks(network_pkl)\r\n","    rnd = np.random\r\n","    fmt = dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True)\r\n","    latent1 = rnd.randn(1,Gs.input_shape[1])\r\n","    latent2 = rnd.randn(1,Gs.input_shape[1])\r\n","    #loop through 10 times and out put interpolated images\r\n","    for i in range(10):\r\n","        factor = float(i)/10\r\n","        l1 = latent1*factor\r\n","        l2 = latent2*(1-factor)\r\n","        combinedLatent = l1+l2\r\n","        current_image = images = Gs.run(combinedLatent,None, truncation_psi=1.0,randomize_noise=False,output_transform=fmt)[0]\r\n","        image = PIL.Image.fromarray(current_image,'RGB')\r\n","        fName = DIR + \"/\"+ \"beast_\" + str(i) + \".png\"\r\n","        image.save(fName)\r\n","\r\n","\r\n","\r\n","\r\n","\r\n","\r\n","\r\n","if __name__ == \"__main__\":\r\n","    main()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ih4I1qCKRdPK"},"source":[""],"execution_count":null,"outputs":[]}]}
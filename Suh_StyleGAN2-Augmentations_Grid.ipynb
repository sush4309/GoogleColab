{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Suh_StyleGAN2-Augmentations_Grid.ipynb","provenance":[{"file_id":"1jmMGOTDM0Y3ftbaGKEXwsr6bViBMxdE0","timestamp":1615264810877},{"file_id":"1UPZWAiXDllrpiGbGMLMHtSxZ2MnALZ1G","timestamp":1614052722802},{"file_id":"https://github.com/dvschultz/ai/blob/master/StyleGAN2_Augmentations.ipynb","timestamp":1597692261353}],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"LvKaOmgoWAsI"},"source":["# StyleGAN2 with Augmentations\n","\n","This notebook shows code for training with image augmentations. For more info on this technique see [Training Generative Adversarial Networks with Limited Data](https://arxiv.org/abs/2006.06676). \n","\n","This code comes from [Sid Black](https://github.com/sdtblck/stylegan2). A huge thanks to him for doing all of this work ðŸ™\n","\n","If this is your first time using StyleGAN2 on Colab I recommend watching some of my YouTube videos first. Start with [this one](https://www.youtube.com/watch?v=hv3A62Ojqdg). A video on this notebook and technique is [here](https://youtu.be/D3a9DFykfxI)"]},{"cell_type":"code","metadata":{"id":"9QtGFQ_PwLFZ","executionInfo":{"status":"ok","timestamp":1615280670830,"user_tz":480,"elapsed":223,"user":{"displayName":"Sanghyun Suh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUdCPmMsqijTthZ24MFHldVLUgCbJtwxfzXlusFw=s64","userId":"03325525587695274031"}}},"source":["#always use tensorflow1\n","\n","%tensorflow_version 1.x\n"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"Gdl_HcPhkTsv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615280689059,"user_tz":480,"elapsed":17419,"user":{"displayName":"Sanghyun Suh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUdCPmMsqijTthZ24MFHldVLUgCbJtwxfzXlusFw=s64","userId":"03325525587695274031"}},"outputId":"42834f5a-2d11-40f0-aec4-e71a44807c5e"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"6I1rJ72VWSY6"},"source":["## Initial Setup\n","\n","Run this cell if youâ€™ve never run this repo in your Drive account. SKIP it if you have."]},{"cell_type":"code","metadata":{"id":"7lSz-7VCkmaK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611367326763,"user_tz":480,"elapsed":26831,"user":{"displayName":"Casey Rehm","photoUrl":"","userId":"14928713571001354102"}},"outputId":"920c9938-4960-4730-8e9d-57bac7c8fb3d"},"source":["#SKIP this if you already have a stylegan2 folder in your google drive\n","%cd /content/drive/MyDrive/\n","!mkdir stylegan2-aug-colab\n","%cd stylegan2-aug-colab/\n","!git clone -b augs-attn https://github.com/dvschultz/stylegan2\n","%cd stylegan2\n","!mkdir pkl\n","%cd pkl\n","!gdown --id 1JLqXE5bGZnlu2BkbLPD5_ZxoO3Nz-AvF #inception: https://drive.google.com/open?id=1JLqXE5bGZnlu2BkbLPD5_ZxoO3Nz-AvF\n","%cd ../\n","!mkdir results\n","!mkdir results/00001-pretrained\n","%cd results/00001-pretrained\n","!gdown --id 1UlDmJVLLnBD9SnLSMXeiZRO6g-OMQCA_\n","%cd ../../\n","%mkdir datasets"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive\n","mkdir: cannot create directory â€˜stylegan2-aug-colabâ€™: File exists\n","/content/drive/MyDrive/stylegan2-aug-colab\n","fatal: destination path 'stylegan2' already exists and is not an empty directory.\n","/content/drive/MyDrive/stylegan2-aug-colab/stylegan2\n","mkdir: cannot create directory â€˜pklâ€™: File exists\n","/content/drive/MyDrive/stylegan2-aug-colab/stylegan2/pkl\n","Downloading...\n","From: https://drive.google.com/uc?id=1JLqXE5bGZnlu2BkbLPD5_ZxoO3Nz-AvF\n","To: /content/drive/MyDrive/stylegan2-aug-colab/stylegan2/pkl/inception_v3_features.pkl\n","87.3MB [00:01, 63.9MB/s]\n","/content/drive/My Drive/stylegan2-aug-colab/stylegan2\n","mkdir: cannot create directory â€˜resultsâ€™: File exists\n","mkdir: cannot create directory â€˜results/00001-pretrainedâ€™: File exists\n","/content/drive/My Drive/stylegan2-aug-colab/stylegan2/results/00001-pretrained\n","Downloading...\n","From: https://drive.google.com/uc?id=1UlDmJVLLnBD9SnLSMXeiZRO6g-OMQCA_\n","To: /content/drive/My Drive/stylegan2-aug-colab/stylegan2/results/00001-pretrained/stylegan2-ffhq-config-f.pkl\n","382MB [00:03, 97.3MB/s]\n","/content/drive/My Drive/stylegan2-aug-colab/stylegan2\n","mkdir: cannot create directory â€˜datasetsâ€™: File exists\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"BsQL8nw9WX6C"},"source":["## Return Setup\n","Run this cell if youâ€™re picking up from a previous training."]},{"cell_type":"code","metadata":{"id":"w9tLYIpHk8WU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615280954659,"user_tz":480,"elapsed":231,"user":{"displayName":"Sanghyun Suh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUdCPmMsqijTthZ24MFHldVLUgCbJtwxfzXlusFw=s64","userId":"03325525587695274031"}},"outputId":"c417da29-468c-404f-92e4-de3947702e02"},"source":["%cd /content/drive/MyDrive/stylegan2-aug-colab/stylegan2\n","#!git pull"],"execution_count":6,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/stylegan2-aug-colab/stylegan2\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"2qbCFYx3Wghn"},"source":["## Training\n","\n","In the next cell set your pkl and `resume_kimg` counter. If this is your first time the settings below should work for you."]},{"cell_type":"code","metadata":{"id":"83hg9Jw9zObb","executionInfo":{"status":"ok","timestamp":1615280989963,"user_tz":480,"elapsed":219,"user":{"displayName":"Sanghyun Suh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUdCPmMsqijTthZ24MFHldVLUgCbJtwxfzXlusFw=s64","userId":"03325525587695274031"}}},"source":["pkl = \"/content/drive/MyDrive/stylegan2-aug-colab/stylegan2/results/00074-stylegan2-SoomeenHahm-1gpu-config-f/network-snapshot-012016.pkl\"\n","resume_kimg = 12016"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fWf6qqV_-UQP"},"source":["if you need to make a dataset run below\n"]},{"cell_type":"markdown","metadata":{"id":"_jN99nH6Ep1S"},"source":["The first address is the destination tf Records file"]},{"cell_type":"code","metadata":{"id":"nHtOsDri-YNm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614657469416,"user_tz":480,"elapsed":113313,"user":{"displayName":"Casey Rehm","photoUrl":"","userId":"14928713571001354102"}},"outputId":"61501a57-584d-4793-ed96-a7d872865514"},"source":["!python dataset_tool.py create_from_images_raw /content/drive/MyDrive/stylegan2-aug-colab/stylegan2/datasets/SoomeenHahm /content/drive/MyDrive/stylegan2-aug-colab/stylegan2/SoomeenImages"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Loading images from \"/content/drive/MyDrive/stylegan2-aug-colab/stylegan2/SoomeenImages\"\n","detected 188 images ...\n","Shuffle the images...\n","Creating dataset \"/content/drive/MyDrive/stylegan2-aug-colab/stylegan2/datasets/SoomeenHahm\"\n","Adding the images to tfrecords ...\n","added images 0\n","Added 188 images.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"EQDK-iofWls5"},"source":["Most of the settings match the skyflynil or pbaylies fork of StyleGAN2. The big difference here is the `AUG_PROB` environment setting. This tells the training loop how often to modify the real and fake images with augmentations. The default is `0.1` If you have a small training set you may want to go higher than that but note that the Karras paper does say if you set this value too high you may find it bleeds into the outputs."]},{"cell_type":"code","metadata":{"id":"LqZAM9ormiYf","colab":{"base_uri":"https://localhost:8080/"},"outputId":"2547759c-1520-4e11-c9e9-8c4adceeddbd"},"source":["!AUG_PROB=0.2 python run_training.py --num-gpus=1 --mirror-augment=True --data-dir=./datasets --dataset=Beast --config=config-f --resume-pkl=$pkl --resume-kimg=$resume_kimg --augmentations=True --metrics=None"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Local submit - run_dir: results/00034-stylegan2-Beast-1gpu-config-f\n","dnnlib: Running training.training_loop.training_loop() on localhost...\n","Streaming data using training.dataset.TFRecordDataset...\n","Dataset shape = [3, 512, 512]\n","Dynamic range = [0, 255]\n","Label size    = 0\n","Loading networks from \"/content/drive/MyDrive/stylegan2-aug-colab/stylegan2/results/00033-stylegan2-Beast-1gpu-config-f/network-snapshot-013837.pkl\"...\n","Setting up TensorFlow plugin \"fused_bias_act.cu\": Preprocessing... Loading... Done.\n","Setting up TensorFlow plugin \"upfirdn_2d.cu\": Preprocessing... Loading... Done.\n","\n","G                             Params    OutputShape         WeightShape     \n","---                           ---       ---                 ---             \n","latents_in                    -         (?, 512)            -               \n","labels_in                     -         (?, 0)              -               \n","lod                           -         ()                  -               \n","dlatent_avg                   -         (512,)              -               \n","G_mapping/latents_in          -         (?, 512)            -               \n","G_mapping/labels_in           -         (?, 0)              -               \n","G_mapping/Normalize           -         (?, 512)            -               \n","G_mapping/Dense0              262656    (?, 512)            (512, 512)      \n","G_mapping/Dense1              262656    (?, 512)            (512, 512)      \n","G_mapping/Dense2              262656    (?, 512)            (512, 512)      \n","G_mapping/Dense3              262656    (?, 512)            (512, 512)      \n","G_mapping/Dense4              262656    (?, 512)            (512, 512)      \n","G_mapping/Dense5              262656    (?, 512)            (512, 512)      \n","G_mapping/Dense6              262656    (?, 512)            (512, 512)      \n","G_mapping/Dense7              262656    (?, 512)            (512, 512)      \n","G_mapping/Broadcast           -         (?, 16, 512)        -               \n","G_mapping/dlatents_out        -         (?, 16, 512)        -               \n","Truncation/Lerp               -         (?, 16, 512)        -               \n","G_synthesis/dlatents_in       -         (?, 16, 512)        -               \n","G_synthesis/4x4/Const         8192      (?, 512, 4, 4)      (1, 512, 4, 4)  \n","G_synthesis/4x4/Conv          2622465   (?, 512, 4, 4)      (3, 3, 512, 512)\n","G_synthesis/4x4/ToRGB         264195    (?, 3, 4, 4)        (1, 1, 512, 3)  \n","G_synthesis/8x8/Conv0_up      2622465   (?, 512, 8, 8)      (3, 3, 512, 512)\n","G_synthesis/8x8/Conv1         2622465   (?, 512, 8, 8)      (3, 3, 512, 512)\n","G_synthesis/8x8/Upsample      -         (?, 3, 8, 8)        -               \n","G_synthesis/8x8/ToRGB         264195    (?, 3, 8, 8)        (1, 1, 512, 3)  \n","G_synthesis/16x16/Conv0_up    2622465   (?, 512, 16, 16)    (3, 3, 512, 512)\n","G_synthesis/16x16/Conv1       2622465   (?, 512, 16, 16)    (3, 3, 512, 512)\n","G_synthesis/16x16/Upsample    -         (?, 3, 16, 16)      -               \n","G_synthesis/16x16/ToRGB       264195    (?, 3, 16, 16)      (1, 1, 512, 3)  \n","G_synthesis/32x32/Conv0_up    2622465   (?, 512, 32, 32)    (3, 3, 512, 512)\n","G_synthesis/32x32/Conv1       2622465   (?, 512, 32, 32)    (3, 3, 512, 512)\n","G_synthesis/32x32/Upsample    -         (?, 3, 32, 32)      -               \n","G_synthesis/32x32/ToRGB       264195    (?, 3, 32, 32)      (1, 1, 512, 3)  \n","G_synthesis/64x64/Conv0_up    2622465   (?, 512, 64, 64)    (3, 3, 512, 512)\n","G_synthesis/64x64/Conv1       2622465   (?, 512, 64, 64)    (3, 3, 512, 512)\n","G_synthesis/64x64/Upsample    -         (?, 3, 64, 64)      -               \n","G_synthesis/64x64/ToRGB       264195    (?, 3, 64, 64)      (1, 1, 512, 3)  \n","G_synthesis/128x128/Conv0_up  1442561   (?, 256, 128, 128)  (3, 3, 512, 256)\n","G_synthesis/128x128/Conv1     721409    (?, 256, 128, 128)  (3, 3, 256, 256)\n","G_synthesis/128x128/Upsample  -         (?, 3, 128, 128)    -               \n","G_synthesis/128x128/ToRGB     132099    (?, 3, 128, 128)    (1, 1, 256, 3)  \n","G_synthesis/256x256/Conv0_up  426369    (?, 128, 256, 256)  (3, 3, 256, 128)\n","G_synthesis/256x256/Conv1     213249    (?, 128, 256, 256)  (3, 3, 128, 128)\n","G_synthesis/256x256/Upsample  -         (?, 3, 256, 256)    -               \n","G_synthesis/256x256/ToRGB     66051     (?, 3, 256, 256)    (1, 1, 128, 3)  \n","G_synthesis/512x512/Conv0_up  139457    (?, 64, 512, 512)   (3, 3, 128, 64) \n","G_synthesis/512x512/Conv1     69761     (?, 64, 512, 512)   (3, 3, 64, 64)  \n","G_synthesis/512x512/Upsample  -         (?, 3, 512, 512)    -               \n","G_synthesis/512x512/ToRGB     33027     (?, 3, 512, 512)    (1, 1, 64, 3)   \n","G_synthesis/images_out        -         (?, 3, 512, 512)    -               \n","G_synthesis/noise0            -         (1, 1, 4, 4)        -               \n","G_synthesis/noise1            -         (1, 1, 8, 8)        -               \n","G_synthesis/noise2            -         (1, 1, 8, 8)        -               \n","G_synthesis/noise3            -         (1, 1, 16, 16)      -               \n","G_synthesis/noise4            -         (1, 1, 16, 16)      -               \n","G_synthesis/noise5            -         (1, 1, 32, 32)      -               \n","G_synthesis/noise6            -         (1, 1, 32, 32)      -               \n","G_synthesis/noise7            -         (1, 1, 64, 64)      -               \n","G_synthesis/noise8            -         (1, 1, 64, 64)      -               \n","G_synthesis/noise9            -         (1, 1, 128, 128)    -               \n","G_synthesis/noise10           -         (1, 1, 128, 128)    -               \n","G_synthesis/noise11           -         (1, 1, 256, 256)    -               \n","G_synthesis/noise12           -         (1, 1, 256, 256)    -               \n","G_synthesis/noise13           -         (1, 1, 512, 512)    -               \n","G_synthesis/noise14           -         (1, 1, 512, 512)    -               \n","images_out                    -         (?, 3, 512, 512)    -               \n","---                           ---       ---                 ---             \n","Total                         30276583                                      \n","\n","\n","D                    Params    OutputShape         WeightShape     \n","---                  ---       ---                 ---             \n","images_in            -         (?, 3, 512, 512)    -               \n","labels_in            -         (?, 0)              -               \n","512x512/FromRGB      256       (?, 64, 512, 512)   (1, 1, 3, 64)   \n","512x512/Conv0        36928     (?, 64, 512, 512)   (3, 3, 64, 64)  \n","512x512/Conv1_down   73856     (?, 128, 256, 256)  (3, 3, 64, 128) \n","512x512/Skip         8192      (?, 128, 256, 256)  (1, 1, 64, 128) \n","256x256/Conv0        147584    (?, 128, 256, 256)  (3, 3, 128, 128)\n","256x256/Conv1_down   295168    (?, 256, 128, 128)  (3, 3, 128, 256)\n","256x256/Skip         32768     (?, 256, 128, 128)  (1, 1, 128, 256)\n","128x128/Conv0        590080    (?, 256, 128, 128)  (3, 3, 256, 256)\n","128x128/Conv1_down   1180160   (?, 512, 64, 64)    (3, 3, 256, 512)\n","128x128/Skip         131072    (?, 512, 64, 64)    (1, 1, 256, 512)\n","64x64/Conv0          2359808   (?, 512, 64, 64)    (3, 3, 512, 512)\n","64x64/Conv1_down     2359808   (?, 512, 32, 32)    (3, 3, 512, 512)\n","64x64/Skip           262144    (?, 512, 32, 32)    (1, 1, 512, 512)\n","32x32/Conv0          2359808   (?, 512, 32, 32)    (3, 3, 512, 512)\n","32x32/Conv1_down     2359808   (?, 512, 16, 16)    (3, 3, 512, 512)\n","32x32/Skip           262144    (?, 512, 16, 16)    (1, 1, 512, 512)\n","16x16/Conv0          2359808   (?, 512, 16, 16)    (3, 3, 512, 512)\n","16x16/Conv1_down     2359808   (?, 512, 8, 8)      (3, 3, 512, 512)\n","16x16/Skip           262144    (?, 512, 8, 8)      (1, 1, 512, 512)\n","8x8/Conv0            2359808   (?, 512, 8, 8)      (3, 3, 512, 512)\n","8x8/Conv1_down       2359808   (?, 512, 4, 4)      (3, 3, 512, 512)\n","8x8/Skip             262144    (?, 512, 4, 4)      (1, 1, 512, 512)\n","4x4/MinibatchStddev  -         (?, 513, 4, 4)      -               \n","4x4/Conv             2364416   (?, 512, 4, 4)      (3, 3, 513, 512)\n","4x4/Dense0           4194816   (?, 512)            (8192, 512)     \n","Output               513       (?, 1)              (512, 1)        \n","scores_out           -         (?, 1)              -               \n","---                  ---       ---                 ---             \n","Total                28982849                                      \n","\n","Building TensorFlow graph...\n","In shape:\n","(4, 3, 512, 512)\n","Augmenting reals and fake in gpu mode\n","Augment probability 0.2\n","Transposing channels\n","POLICY :  random\n","In shape:\n","(4, 3, 512, 512)\n","Augmenting reals and fake in gpu mode\n","Augment probability 0.2\n","Transposing channels\n","POLICY :  random\n","In shape:\n","(4, 3, 512, 512)\n","Augmenting reals and fake in gpu mode\n","Augment probability 0.2\n","Transposing channels\n","POLICY :  random\n","Initializing logs...\n","Training for 25000 kimg...\n","\n","tick 0     kimg 13837.1  lod 0.00  minibatch 32   time 57s          sec/tick 57.2    sec/kimg 446.68  maintenance 0.0    gpumem 8.5\n","tick 1     kimg 13843.1  lod 0.00  minibatch 32   time 17m 12s      sec/tick 957.7   sec/kimg 159.19  maintenance 17.0   gpumem 8.5\n","tick 2     kimg 13849.2  lod 0.00  minibatch 32   time 33m 19s      sec/tick 960.5   sec/kimg 159.65  maintenance 6.3    gpumem 8.5\n","tick 3     kimg 13855.2  lod 0.00  minibatch 32   time 49m 23s      sec/tick 959.3   sec/kimg 159.45  maintenance 4.6    gpumem 8.5\n","tick 4     kimg 13861.2  lod 0.00  minibatch 32   time 1h 05m 28s   sec/tick 960.2   sec/kimg 159.60  maintenance 4.8    gpumem 8.5\n","tick 5     kimg 13867.2  lod 0.00  minibatch 32   time 1h 21m 30s   sec/tick 957.8   sec/kimg 159.22  maintenance 4.8    gpumem 8.5\n","tick 6     kimg 13873.2  lod 0.00  minibatch 32   time 1h 37m 35s   sec/tick 959.7   sec/kimg 159.53  maintenance 4.7    gpumem 8.5\n","tick 7     kimg 13879.2  lod 0.00  minibatch 32   time 1h 53m 40s   sec/tick 960.3   sec/kimg 159.63  maintenance 4.9    gpumem 8.5\n","tick 8     kimg 13885.3  lod 0.00  minibatch 32   time 2h 09m 44s   sec/tick 959.9   sec/kimg 159.57  maintenance 4.6    gpumem 8.5\n","tick 9     kimg 13891.3  lod 0.00  minibatch 32   time 2h 25m 49s   sec/tick 959.7   sec/kimg 159.52  maintenance 5.1    gpumem 8.5\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pt7jqKQ4wHZe"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"F3fccHsWMXGL"},"source":["# Projection\n","Once the network is trained we can project in selected images.  The first step is to create a dataset file for those images.\n"]},{"cell_type":"code","metadata":{"id":"fiCR5knmMcQ1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614153188179,"user_tz":480,"elapsed":22682,"user":{"displayName":"Casey Rehm","photoUrl":"","userId":"14928713571001354102"}},"outputId":"314a0879-ee5e-4c96-ff56-44dcf0938122"},"source":["!python dataset_tool.py create_from_images_raw /content/drive/MyDrive/stylegan2-aug-colab/stylegan2/datasets/ProjectFiles /content/drive/MyDrive/stylegan2-aug-colab/stylegan2/projectMe"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Loading images from \"/content/drive/MyDrive/stylegan2-aug-colab/stylegan2/projectMe\"\n","detected 45 images ...\n","Shuffle the images...\n","Creating dataset \"/content/drive/MyDrive/stylegan2-aug-colab/stylegan2/datasets/ProjectFiles\"\n","Adding the images to tfrecords ...\n","added images 0\n","Added 45 images.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"3nDUrNJjNp0U"},"source":["Once the new dataset for projection is created you can run this to produce the outputs.\n","\n","\n","1.   set the network flag to the location of your most recent output .pkl\n","2.   check your dataset name and dir\n","\n"]},{"cell_type":"code","metadata":{"id":"g4fd0sT6N0pX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614154610503,"user_tz":480,"elapsed":920381,"user":{"displayName":"Casey Rehm","photoUrl":"","userId":"14928713571001354102"}},"outputId":"ae599dce-7fc1-46af-db23-b7b49d9a00b7"},"source":["!python run_projector.py project-real-images --network=/content/drive/MyDrive/stylegan2-aug-colab/stylegan2/results/00007-stylegan2-Ginza-1gpu-config-f/network-snapshot-010054.pkl --dataset=ProjectFiles --data-dir=/content/drive/MyDrive/stylegan2-aug-colab/stylegan2/datasets --num-images=45"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Local submit - run_dir: results/00010-project-real-images\n","dnnlib: Running run_projector.project_real_images() on localhost...\n","Loading networks from \"/content/drive/MyDrive/stylegan2-aug-colab/stylegan2/results/00007-stylegan2-Ginza-1gpu-config-f/network-snapshot-010054.pkl\"...\n","Setting up TensorFlow plugin \"fused_bias_act.cu\": Preprocessing... Loading... Done.\n","Setting up TensorFlow plugin \"upfirdn_2d.cu\": Preprocessing... Loading... Done.\n","Loading images from \"ProjectFiles\"...\n","Projecting image 0/45 ...\n","Projecting image 1/45 ...\n","Projecting image 2/45 ...\n","Projecting image 3/45 ...\n","Projecting image 4/45 ...\n","Projecting image 5/45 ...\n","Projecting image 6/45 ...\n","Projecting image 7/45 ...\n","Projecting image 8/45 ...\n","Projecting image 9/45 ...\n","Projecting image 10/45 ...\n","Projecting image 11/45 ...\n","Projecting image 12/45 ...\n","Projecting image 13/45 ...\n","Projecting image 14/45 ...\n","Projecting image 15/45 ...\n","Projecting image 16/45 ...\n","Projecting image 17/45 ...\n","Projecting image 18/45 ...\n","Projecting image 19/45 ...\n","Projecting image 20/45 ...\n","Projecting image 21/45 ...\n","Projecting image 22/45 ...\n","Projecting image 23/45 ...\n","Projecting image 24/45 ...\n","Projecting image 25/45 ...\n","Projecting image 26/45 ...\n","Projecting image 27/45 ...\n","Projecting image 28/45 ...\n","Projecting image 29/45 ...\n","Projecting image 30/45 ...\n","Projecting image 31/45 ...\n","Projecting image 32/45 ...\n","Projecting image 33/45 ...\n","Projecting image 34/45 ...\n","Projecting image 35/45 ...\n","Projecting image 36/45 ...\n","Projecting image 37/45 ...\n","Projecting image 38/45 ...\n","Projecting image 39/45 ...\n","Projecting image 40/45 ...\n","Projecting image 41/45 ...\n","Projecting image 42/45 ...\n","Projecting image 43/45 ...\n","Projecting image 44/45 ...\n","dnnlib: Finished run_projector.project_real_images() in 15m 15s.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"u6fhXCgmksF_"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MIAN2b-FP6I4"},"source":["# RandomImage Generation and Interpolation"]},{"cell_type":"code","metadata":{"id":"ExDOud8RYO6b","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615281002662,"user_tz":480,"elapsed":351,"user":{"displayName":"Sanghyun Suh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUdCPmMsqijTthZ24MFHldVLUgCbJtwxfzXlusFw=s64","userId":"03325525587695274031"}},"outputId":"e541f3e6-0980-443a-b00f-7b9ca8caeb88"},"source":["%cd /content/drive/MyDrive/stylegan2-aug-colab/stylegan2"],"execution_count":9,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/stylegan2-aug-colab/stylegan2\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"J-DT1F9eXAEo"},"source":["This code will create a sequence of png's smoothly blending between random points in the network.   \n","\n","1.   Change line 41 to your network\n","2.   Change Tokyo to your image name on line 83\n","\n"]},{"cell_type":"code","metadata":{"id":"1Sgpu8xQQC5u","colab":{"base_uri":"https://localhost:8080/","height":374},"executionInfo":{"status":"error","timestamp":1615281024253,"user_tz":480,"elapsed":354,"user":{"displayName":"Sanghyun Suh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUdCPmMsqijTthZ24MFHldVLUgCbJtwxfzXlusFw=s64","userId":"03325525587695274031"}},"outputId":"c8ad6d9b-9638-4f64-8283-251391294ba3"},"source":["# Copyright (c) 2019, NVIDIA Corporation. All rights reserved.\n","#\n","# This work is made available under the Nvidia Source Code License-NC.\n","# To view a copy of this license, visit\n","# https://nvlabs.github.io/stylegan2/license.html\n","\n","import argparse\n","import numpy as np\n","import PIL.Image\n","import dnnlib\n","import dnnlib.tflib as tflib\n","\n","\n","import pretrained_networks\n","\n","#----------------------------------------------------------------------------\n","def create_image_grid(images, grid_size=None):\n","    assert images.ndim == 3 or images.ndim == 4\n","    num, img_h, img_w, channels = images.shape\n","\n","    if grid_size is not None:\n","        grid_w, grid_h = tuple(grid_size)\n","    else:\n","        grid_w = max(int(np.ceil(np.sqrt(num))), 1)\n","        grid_h = max((num - 1) // grid_w + 1, 1)\n","\n","    grid = np.zeros([grid_h * img_h, grid_w * img_w, channels], dtype=images.dtype)\n","    for idx in range(num):\n","        x = (idx % grid_w) * img_w\n","        y = (idx // grid_w) * img_h\n","        grid[y: y + img_h, x: x + img_w] = images[idx]\n","    return grid\n","\n","def genGrid():\n","\n","    tflib.init_tf()\n","\n","    # Load pre-trained network.\n","\n","    ## NOTE: insert model here:\n","    _G, _D, Gs = pretrained_networks.load_networks(\"network-snapshot-012016.pkl\")\n","\n","\n","    grid_size = [8,5]\n","\n","    image_zoom = 1\n","    duration_sec = 60\n","    smoothing_sec = .5\n","    mp4_fps = 24\n","    random_seed = 8004\n","    minibatch_size = 8\n","    cnt = 0\n","    num_frames = int(np.rint(duration_sec * mp4_fps))\n","    random_state = np.random.RandomState(random_seed)\n","\n","    # Generate latent vectors\n","    shape = [num_frames, np.prod(grid_size)] + Gs.input_shape[1:] # [frame, image, channel, component]\n","    all_latents = random_state.randn(*shape).astype(np.float32)\n","    import scipy\n","    all_latents = scipy.ndimage.gaussian_filter(all_latents, [smoothing_sec * mp4_fps] + [0] * len(Gs.input_shape), mode='wrap')\n","    all_latents /= np.sqrt(np.mean(np.square(all_latents)))\n","\n","\n","    # Frame generation func for moviepy.\n","    for t in range(num_frames):\n","        v = t/24\n","        frame_idx = int(np.clip(np.round(v * mp4_fps), 0, num_frames - 1))\n","        latents = all_latents[frame_idx]\n","        fmt = dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True)\n","        images = Gs.run(latents, None, truncation_psi=0.75,\n","                              randomize_noise=False, output_transform=fmt)\n","\n","        grid = create_image_grid(images, grid_size)\n","        if image_zoom > 1:\n","            grid = scipy.ndimage.zoom(grid, [image_zoom, image_zoom, 1], order=0)\n","        if grid.shape[2] == 1:\n","            grid = grid.repeat(3, 2) # grayscale => RGB\n","        canvas = PIL.Image.fromarray(grid)\n","        cnt = t\n","        #cnt = int(t*24)\n","        cnt = \"{:04d}\".format(cnt)\n","        print(cnt)\n","        fName = 'images/BeastTotal_' + str(cnt) + '.png'\n","\n","\n","        canvas.save(fName)\n","        #return grid\n","\n","\n","\n","\n","def main():\n","   genGrid()\n","\n","#----------------------------------------------------------------------------\n","\n","if __name__ == \"__main__\":\n","    main()\n","\n","#----------------------------------------------------------------------------\n"],"execution_count":11,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-5b1e6832eac6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;31m#----------------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-11-5b1e6832eac6>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m    \u001b[0mgenGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;31m#----------------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-11-5b1e6832eac6>\u001b[0m in \u001b[0;36mgenGrid\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;31m## NOTE: insert model here:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0m_G\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpretrained_networks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_networks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"network-snapshot-012016.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/My Drive/stylegan2-aug-colab/stylegan2/pretrained_networks.py\u001b[0m in \u001b[0;36mload_networks\u001b[0;34m(path_or_gdrive_path)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdnnlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'.stylegan2-cache'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0mstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0mtflib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_tf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'network-snapshot-012016.pkl'"]}]},{"cell_type":"code","metadata":{"id":"lPSR0OGvZo9Q"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4TiDbmc21Yuw"},"source":["# **StyleMixing Grid Production**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":374},"id":"LBV0WZ0b1db3","executionInfo":{"status":"error","timestamp":1615281092365,"user_tz":480,"elapsed":1068,"user":{"displayName":"Sanghyun Suh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUdCPmMsqijTthZ24MFHldVLUgCbJtwxfzXlusFw=s64","userId":"03325525587695274031"}},"outputId":"11313989-bada-4e17-f513-e170bc88d27f"},"source":["# Copyright (c) 2019, NVIDIA CORPORATION. All rights reserved.\r\n","#\r\n","# This work is licensed under the Creative Commons Attribution-NonCommercial\r\n","# 4.0 International License. To view a copy of this license, visit\r\n","# http://creativecommons.org/licenses/by-nc/4.0/ or send a letter to\r\n","# Creative Commons, PO Box 1866, Mountain View, CA 94042, USA.\r\n","\r\n","\"\"\"Minimal script for reproducing the figures of the StyleGAN paper using pre-trained generators.\"\"\"\r\n","\r\n","import os\r\n","import pickle\r\n","import numpy as np\r\n","import PIL.Image\r\n","import dnnlib\r\n","import dnnlib.tflib as tflib\r\n","\r\n","\r\n","#----------------------------------------------------------------------------\r\n","# Helpers for loading and using pre-trained generators.\r\n","\r\n","\r\n","\r\n","synthesis_kwargs = dict(output_transform=dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True), minibatch_size=8)\r\n","\r\n","_Gs_cache = dict()\r\n","\r\n","# def load_Gs(url):\r\n","#     if url not in _Gs_cache:\r\n","#         with dnnlib.util.open_url(url, cache_dir=config.cache_dir) as f:\r\n","#             _G, _D, Gs = pickle.load(f)\r\n","#         _Gs_cache[url] = Gs\r\n","#     return _Gs_cache[url]\r\n","def load_Gs():\r\n","    _G, _D, Gs = pickle.load(open(\"network-snapshot-012016.pkl\",\"rb\"))\r\n","    return Gs\r\n","#----------------------------------------------------------------------------\r\n","# Figures 2, 3, 10, 11, 12: Multi-resolution grid of uncurated result images.\r\n","\r\n","def draw_uncurated_result_figure(png, Gs, cx, cy, cw, ch, rows, lods, seed):\r\n","    print(png)\r\n","    latents = np.random.RandomState(seed).randn(sum(rows * 2**lod for lod in lods), Gs.input_shape[1])\r\n","    images = Gs.run(latents, None, **synthesis_kwargs) # [seed, y, x, rgb]\r\n","\r\n","    canvas = PIL.Image.new('RGB', (sum(cw // 2**lod for lod in lods), ch * rows), 'white')\r\n","    image_iter = iter(list(images))\r\n","    for col, lod in enumerate(lods):\r\n","        for row in range(rows * 2**lod):\r\n","            image = PIL.Image.fromarray(next(image_iter), 'RGB')\r\n","            image = image.crop((cx, cy, cx + cw, cy + ch))\r\n","            image = image.resize((cw // 2**lod, ch // 2**lod), PIL.Image.ANTIALIAS)\r\n","            canvas.paste(image, (sum(cw // 2**lod for lod in lods[:col]), row * ch // 2**lod))\r\n","    canvas.save(png)\r\n","\r\n","#----------------------------------------------------------------------------\r\n","# Figure 3: Style mixing.\r\n","\r\n","def draw_style_mixing_figure(png, Gs, w, h, src_seeds, dst_seeds, style_ranges):\r\n","    print(png)\r\n","    src_latents = np.stack(np.random.RandomState(seed).randn(Gs.input_shape[1]) for seed in src_seeds)\r\n","    dst_latents = np.stack(np.random.RandomState(seed).randn(Gs.input_shape[1]) for seed in dst_seeds)\r\n","    src_dlatents = Gs.components.mapping.run(src_latents, None) # [seed, layer, component]\r\n","    dst_dlatents = Gs.components.mapping.run(dst_latents, None) # [seed, layer, component]\r\n","    src_images = Gs.components.synthesis.run(src_dlatents, randomize_noise=False, **synthesis_kwargs)\r\n","    dst_images = Gs.components.synthesis.run(dst_dlatents, randomize_noise=False, **synthesis_kwargs)\r\n","\r\n","    canvas = PIL.Image.new('RGB', (w * (len(src_seeds) + 1), h * (len(dst_seeds) + 1)), 'white')\r\n","    for col, src_image in enumerate(list(src_images)):\r\n","        canvas.paste(PIL.Image.fromarray(src_image, 'RGB'), ((col + 1) * w, 0))\r\n","    for row, dst_image in enumerate(list(dst_images)):\r\n","        canvas.paste(PIL.Image.fromarray(dst_image, 'RGB'), (0, (row + 1) * h))\r\n","        row_dlatents = np.stack([dst_dlatents[row]] * len(src_seeds))\r\n","        row_dlatents[:, style_ranges[row]] = src_dlatents[:, style_ranges[row]]\r\n","        row_images = Gs.components.synthesis.run(row_dlatents, randomize_noise=False, **synthesis_kwargs)\r\n","        for col, image in enumerate(list(row_images)):\r\n","            canvas.paste(PIL.Image.fromarray(image, 'RGB'), ((col + 1) * w, (row + 1) * h))\r\n","    canvas.save(png)\r\n","\r\n","#----------------------------------------------------------------------------\r\n","# Figure 4: Noise detail.\r\n","\r\n","def draw_noise_detail_figure(png, Gs, w, h, num_samples, seeds):\r\n","    print(png)\r\n","    canvas = PIL.Image.new('RGB', (w * 3, h * len(seeds)), 'white')\r\n","    for row, seed in enumerate(seeds):\r\n","        latents = np.stack([np.random.RandomState(seed).randn(Gs.input_shape[1])] * num_samples)\r\n","        images = Gs.run(latents, None, truncation_psi=1, **synthesis_kwargs)\r\n","        canvas.paste(PIL.Image.fromarray(images[0], 'RGB'), (0, row * h))\r\n","        for i in range(4):\r\n","            crop = PIL.Image.fromarray(images[i + 1], 'RGB')\r\n","            crop = crop.crop((650, 180, 906, 436))\r\n","            crop = crop.resize((w//2, h//2), PIL.Image.NEAREST)\r\n","            canvas.paste(crop, (w + (i%2) * w//2, row * h + (i//2) * h//2))\r\n","        diff = np.std(np.mean(images, axis=3), axis=0) * 4\r\n","        diff = np.clip(diff + 0.5, 0, 255).astype(np.uint8)\r\n","        canvas.paste(PIL.Image.fromarray(diff, 'L'), (w * 2, row * h))\r\n","    canvas.save(png)\r\n","\r\n","#----------------------------------------------------------------------------\r\n","# Figure 5: Noise components.\r\n","\r\n","def draw_noise_components_figure(png, Gs, w, h, seeds, noise_ranges, flips):\r\n","    print(png)\r\n","    Gsc = Gs.clone()\r\n","    noise_vars = [var for name, var in Gsc.components.synthesis.vars.items() if name.startswith('noise')]\r\n","    noise_pairs = list(zip(noise_vars, tflib.run(noise_vars))) # [(var, val), ...]\r\n","    latents = np.stack(np.random.RandomState(seed).randn(Gs.input_shape[1]) for seed in seeds)\r\n","    all_images = []\r\n","    for noise_range in noise_ranges:\r\n","        tflib.set_vars({var: val * (1 if i in noise_range else 0) for i, (var, val) in enumerate(noise_pairs)})\r\n","        range_images = Gsc.run(latents, None, truncation_psi=1, randomize_noise=False, **synthesis_kwargs)\r\n","        range_images[flips, :, :] = range_images[flips, :, ::-1]\r\n","        all_images.append(list(range_images))\r\n","\r\n","    canvas = PIL.Image.new('RGB', (w * 2, h * 2), 'white')\r\n","    for col, col_images in enumerate(zip(*all_images)):\r\n","        canvas.paste(PIL.Image.fromarray(col_images[0], 'RGB').crop((0, 0, w//2, h)), (col * w, 0))\r\n","        canvas.paste(PIL.Image.fromarray(col_images[1], 'RGB').crop((w//2, 0, w, h)), (col * w + w//2, 0))\r\n","        canvas.paste(PIL.Image.fromarray(col_images[2], 'RGB').crop((0, 0, w//2, h)), (col * w, h))\r\n","        canvas.paste(PIL.Image.fromarray(col_images[3], 'RGB').crop((w//2, 0, w, h)), (col * w + w//2, h))\r\n","    canvas.save(png)\r\n","\r\n","#----------------------------------------------------------------------------\r\n","# Figure 8: Truncation trick.\r\n","\r\n","def draw_truncation_trick_figure(png, Gs, w, h, seeds, psis):\r\n","    print(png)\r\n","    latents = np.stack(np.random.RandomState(seed).randn(Gs.input_shape[1]) for seed in seeds)\r\n","    dlatents = Gs.components.mapping.run(latents, None) # [seed, layer, component]\r\n","    dlatent_avg = Gs.get_var('dlatent_avg') # [component]\r\n","\r\n","    canvas = PIL.Image.new('RGB', (w * len(psis), h * len(seeds)), 'white')\r\n","    for row, dlatent in enumerate(list(dlatents)):\r\n","        row_dlatents = (dlatent[np.newaxis] - dlatent_avg) * np.reshape(psis, [-1, 1, 1]) + dlatent_avg\r\n","        row_images = Gs.components.synthesis.run(row_dlatents, randomize_noise=False, **synthesis_kwargs)\r\n","        for col, image in enumerate(list(row_images)):\r\n","            canvas.paste(PIL.Image.fromarray(image, 'RGB'), (col * w, row * h))\r\n","    canvas.save(png)\r\n","\r\n","#----------------------------------------------------------------------------\r\n","# Main program.\r\n","\r\n","def main():\r\n","    tflib.init_tf()\r\n","    DIR = \"StyleMix\"\r\n","    os.makedirs(DIR, exist_ok=True)\r\n","\r\n","    startSeed = 800\r\n","    startDis = 200\r\n","    startPsi = 1\r\n","    quant = 16\r\n","    seedList = []\r\n","\r\n","    distList = []\r\n","    psiList = []\r\n","\r\n","    dimStep = 2/quant\r\n","\r\n","\r\n","    for i in range(quant):\r\n","        tempSeed = startSeed+ i\r\n","        tempDis = startDis +i\r\n","        seedList.append(tempSeed)\r\n","        if(i > 0):\r\n","            distList.append(tempDis)\r\n","        if(i%2 == 0):\r\n","            tempPsi = startPsi - (i * dimStep)\r\n","            psiList.append(tempPsi)\r\n","\r\n","    \r\n","    draw_style_mixing_figure(os.path.join(DIR, 'BeastMix2.png'), load_Gs(), w=512, h=512, src_seeds=distList, dst_seeds=seedList, style_ranges=[range(0,4)]*16+[range(4,8)]*15+[range(8,16)])\r\n","    \r\n","\r\n","#----------------------------------------------------------------------------\r\n","\r\n","if __name__ == \"__main__\":\r\n","    main()\r\n","\r\n","#----------------------------------------------------------------------------\r\n"],"execution_count":12,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-e1f114749824>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;31m#----------------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-12-e1f114749824>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m     \u001b[0mdraw_style_mixing_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'BeastMix2.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_Gs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_seeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdistList\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst_seeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseedList\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstyle_ranges\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-12-e1f114749824>\u001b[0m in \u001b[0;36mload_Gs\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m#     return _Gs_cache[url]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_Gs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0m_G\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"network-snapshot-012016.pkl\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mGs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m#----------------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'network-snapshot-012016.pkl'"]}]},{"cell_type":"code","metadata":{"id":"at1uqr6hLf5Q"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NE46C1mZOX3n"},"source":["Quick Linear Interpolation"]},{"cell_type":"code","metadata":{"id":"SnH4lFXBOWt4"},"source":["import os\r\n","import pickle\r\n","import numpy as np\r\n","import PIL.Image\r\n","import dnnlib\r\n","import dnnlib.tflib as tflib\r\n","\r\n","\r\n","def main():\r\n","    DIR = \"Blend\"\r\n","    os.makedirs(DIR, exist_ok=True)\r\n","    network_pkl = \"BeastTotal-013891.pkl\"\r\n","    _G, _D, Gs = pretrained_networks.load_networks(network_pkl)\r\n","    rnd = np.random\r\n","    fmt = dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True)\r\n","    latent1 = rnd.randn(1,Gs.input_shape[1])\r\n","    latent2 = rnd.randn(1,Gs.input_shape[1])\r\n","    #loop through 10 times and out put interpolated images\r\n","    for i in range(10):\r\n","        factor = float(i)/10\r\n","        l1 = latent1*factor\r\n","        l2 = latent2*(1-factor)\r\n","        combinedLatent = l1+l2\r\n","        current_image = images = Gs.run(combinedLatent,None, truncation_psi=1.0,randomize_noise=False,output_transform=fmt)[0]\r\n","        image = PIL.Image.fromarray(current_image,'RGB')\r\n","        fName = DIR + \"/\"+ \"beast_\" + str(i) + \".png\"\r\n","        image.save(fName)\r\n","\r\n","\r\n","\r\n","\r\n","\r\n","\r\n","\r\n","if __name__ == \"__main__\":\r\n","    main()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ih4I1qCKRdPK"},"source":[""],"execution_count":null,"outputs":[]}]}
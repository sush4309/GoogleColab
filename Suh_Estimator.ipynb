{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Suh_Estimator.ipynb","provenance":[{"file_id":"1EaBDbrjzFDKPccmF8Cj464gCMHdpKtNq","timestamp":1611195242533}],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"kG6ba8jPpZay","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611793892019,"user_tz":480,"elapsed":14537,"user":{"displayName":"Sanghyun Suh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUdCPmMsqijTthZ24MFHldVLUgCbJtwxfzXlusFw=s64","userId":"03325525587695274031"}},"outputId":"04f90493-7971-48bb-8d47-852ed99ca18e"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"As1t2-pspusG"},"source":["navigate to Case Research folder"]},{"cell_type":"code","metadata":{"id":"Njt9o_n_qiJh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611793895968,"user_tz":480,"elapsed":722,"user":{"displayName":"Sanghyun Suh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUdCPmMsqijTthZ24MFHldVLUgCbJtwxfzXlusFw=s64","userId":"03325525587695274031"}},"outputId":"98574ef4-2b22-44b0-ddfa-27ee9127a38a"},"source":["%cd /content/drive/MyDrive/twitterScrape"],"execution_count":6,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/twitterScrape\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"s4c-uc_FtoCk"},"source":["Set Tensorflow to  1.15"]},{"cell_type":"code","metadata":{"id":"byDXXVHosdq0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611793898108,"user_tz":480,"elapsed":417,"user":{"displayName":"Sanghyun Suh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUdCPmMsqijTthZ24MFHldVLUgCbJtwxfzXlusFw=s64","userId":"03325525587695274031"}},"outputId":"b48459b2-cdd9-4b72-cc1e-9a4d196ddcc8"},"source":["%tensorflow_version 1.x"],"execution_count":7,"outputs":[{"output_type":"stream","text":["TensorFlow 1.x selected.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"_pSyGXyWtlGI"},"source":["Install needed libraries here"]},{"cell_type":"code","metadata":{"id":"2tVzmr_ttfPk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611793914902,"user_tz":480,"elapsed":15942,"user":{"displayName":"Sanghyun Suh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUdCPmMsqijTthZ24MFHldVLUgCbJtwxfzXlusFw=s64","userId":"03325525587695274031"}},"outputId":"e324d02e-4ec0-4d9a-d4a7-0081813cb8c0"},"source":["!apt install -qq enchant\n","!pip install pyenchant"],"execution_count":8,"outputs":[{"output_type":"stream","text":["The following additional packages will be installed:\n","  aspell aspell-en dictionaries-common emacsen-common hunspell-en-us\n","  libaspell15 libenchant1c2a libhunspell-1.6-0 libtext-iconv-perl\n","Suggested packages:\n","  aspell-doc spellutils wordlist hunspell openoffice.org-hunspell\n","  | openoffice.org-core libenchant-voikko\n","The following NEW packages will be installed:\n","  aspell aspell-en dictionaries-common emacsen-common enchant hunspell-en-us\n","  libaspell15 libenchant1c2a libhunspell-1.6-0 libtext-iconv-perl\n","0 upgraded, 10 newly installed, 0 to remove and 13 not upgraded.\n","Need to get 1,310 kB of archives.\n","After this operation, 5,353 kB of additional disk space will be used.\n","Preconfiguring packages ...\n","Selecting previously unselected package libtext-iconv-perl.\n","(Reading database ... 146374 files and directories currently installed.)\n","Preparing to unpack .../0-libtext-iconv-perl_1.7-5build6_amd64.deb ...\n","Unpacking libtext-iconv-perl (1.7-5build6) ...\n","Selecting previously unselected package libaspell15:amd64.\n","Preparing to unpack .../1-libaspell15_0.60.7~20110707-4ubuntu0.1_amd64.deb ...\n","Unpacking libaspell15:amd64 (0.60.7~20110707-4ubuntu0.1) ...\n","Selecting previously unselected package emacsen-common.\n","Preparing to unpack .../2-emacsen-common_2.0.8_all.deb ...\n","Unpacking emacsen-common (2.0.8) ...\n","Selecting previously unselected package dictionaries-common.\n","Preparing to unpack .../3-dictionaries-common_1.27.2_all.deb ...\n","Adding 'diversion of /usr/share/dict/words to /usr/share/dict/words.pre-dictionaries-common by dictionaries-common'\n","Unpacking dictionaries-common (1.27.2) ...\n","Selecting previously unselected package aspell.\n","Preparing to unpack .../4-aspell_0.60.7~20110707-4ubuntu0.1_amd64.deb ...\n","Unpacking aspell (0.60.7~20110707-4ubuntu0.1) ...\n","Selecting previously unselected package aspell-en.\n","Preparing to unpack .../5-aspell-en_2017.08.24-0-0.1_all.deb ...\n","Unpacking aspell-en (2017.08.24-0-0.1) ...\n","Selecting previously unselected package hunspell-en-us.\n","Preparing to unpack .../6-hunspell-en-us_1%3a2017.08.24_all.deb ...\n","Unpacking hunspell-en-us (1:2017.08.24) ...\n","Selecting previously unselected package libhunspell-1.6-0:amd64.\n","Preparing to unpack .../7-libhunspell-1.6-0_1.6.2-1_amd64.deb ...\n","Unpacking libhunspell-1.6-0:amd64 (1.6.2-1) ...\n","Selecting previously unselected package libenchant1c2a:amd64.\n","Preparing to unpack .../8-libenchant1c2a_1.6.0-11.1_amd64.deb ...\n","Unpacking libenchant1c2a:amd64 (1.6.0-11.1) ...\n","Selecting previously unselected package enchant.\n","Preparing to unpack .../9-enchant_1.6.0-11.1_amd64.deb ...\n","Unpacking enchant (1.6.0-11.1) ...\n","Setting up libhunspell-1.6-0:amd64 (1.6.2-1) ...\n","Setting up libaspell15:amd64 (0.60.7~20110707-4ubuntu0.1) ...\n","Setting up emacsen-common (2.0.8) ...\n","Setting up libtext-iconv-perl (1.7-5build6) ...\n","Setting up dictionaries-common (1.27.2) ...\n","Setting up aspell (0.60.7~20110707-4ubuntu0.1) ...\n","Setting up hunspell-en-us (1:2017.08.24) ...\n","Setting up libenchant1c2a:amd64 (1.6.0-11.1) ...\n","Setting up aspell-en (2017.08.24-0-0.1) ...\n","Setting up enchant (1.6.0-11.1) ...\n","Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n","/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n","\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n","Processing triggers for dictionaries-common (1.27.2) ...\n","aspell-autobuildhash: processing: en [en-common].\n","aspell-autobuildhash: processing: en [en-variant_0].\n","aspell-autobuildhash: processing: en [en-variant_1].\n","aspell-autobuildhash: processing: en [en-variant_2].\n","aspell-autobuildhash: processing: en [en-w_accents-only].\n","aspell-autobuildhash: processing: en [en-wo_accents-only].\n","aspell-autobuildhash: processing: en [en_AU-variant_0].\n","aspell-autobuildhash: processing: en [en_AU-variant_1].\n","aspell-autobuildhash: processing: en [en_AU-w_accents-only].\n","aspell-autobuildhash: processing: en [en_AU-wo_accents-only].\n","aspell-autobuildhash: processing: en [en_CA-variant_0].\n","aspell-autobuildhash: processing: en [en_CA-variant_1].\n","aspell-autobuildhash: processing: en [en_CA-w_accents-only].\n","aspell-autobuildhash: processing: en [en_CA-wo_accents-only].\n","aspell-autobuildhash: processing: en [en_GB-ise-w_accents-only].\n","aspell-autobuildhash: processing: en [en_GB-ise-wo_accents-only].\n","aspell-autobuildhash: processing: en [en_GB-ize-w_accents-only].\n","aspell-autobuildhash: processing: en [en_GB-ize-wo_accents-only].\n","aspell-autobuildhash: processing: en [en_GB-variant_0].\n","aspell-autobuildhash: processing: en [en_GB-variant_1].\n","aspell-autobuildhash: processing: en [en_US-w_accents-only].\n","aspell-autobuildhash: processing: en [en_US-wo_accents-only].\n","Collecting pyenchant\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/8c/bd224a5db562ac008edbfaf015f5d5c98ea13e745247cd4ab5fc5b683085/pyenchant-3.2.0-py3-none-any.whl (55kB)\n","\u001b[K     |████████████████████████████████| 61kB 6.4MB/s \n","\u001b[?25hInstalling collected packages: pyenchant\n","Successfully installed pyenchant-3.2.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"QVwW1-uqryRs"},"source":["TwitterClassify"]},{"cell_type":"code","metadata":{"id":"zLn9r1GnrVnE","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1603158993677,"user_tz":420,"elapsed":4646,"user":{"displayName":"Casey Rehm","photoUrl":"","userId":"14928713571001354102"}},"outputId":"230129ec-3703-48c8-ab2b-cdcb830198dc"},"source":["import string\n","import time\n","import os\n","import tensorflow as tf\n","from tensorflow.contrib import predictor\n","import numpy as np\n","import pandas as pd\n","import os\n","import enchant\n","import csv\n","\n","\n","def _bytes_feature(value):\n","    bValue = bytes(value, 'utf-8')\n","    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[bValue]))\n","\n","\n","def runPrediction(msg, predModel):\n","    nMsg = msg;\n","\n","    feature = {\n","        'tweetText': _bytes_feature(nMsg)\n","    }\n","    example = tf.train.Example(\n","        features=tf.train.Features(\n","            feature=feature\n","        )\n","    )\n","    serialized_example = example.SerializeToString()\n","    results = predModel({\"inputs\": [serialized_example]})\n","    results = results.get('scores')[0]\n","    print(results)\n","    results = str(results).strip('[')\n","    results = str(results).strip(']')\n","    return results\n","\n","def main():\n","    top_emotions = [\"robbysoave\", \"RBReich\", \"PalmerReport\", \"AddInfoOrg\",\"Public_Citizen\",\"jimsciutto\", \"DouglasKMurray\",\"MattWalshBlog\", \"realdonaldtrump\", \"tuckercarlson\", \"JesseKellyDC\"]\n","    top_emotions.sort()\n","    headCats = [\"emotions\",\"tweetText\"]\n","    headCats.extend(top_emotions)\n","    en_us = enchant.Dict(\"en_US\")\n","    csvFile = open('twitter_Categories.csv', 'w', newline='')\n","    csvWriter = csv.writer(csvFile)\n","    csvWriter.writerow(headCats)\n","    #load trained model\n","    predict_fn = predictor.from_saved_model(\"export/1602022423\")\n","\n","    data = pd.read_csv('reddit_hot_NNN_v7.csv', header=0)\n","    #np.random.shuffle(data.values[1:, :])\n","    data.head()\n","    # tweetText is the text being evaluated\n","    tweetText = data['tweetText']\n","    data['emotions'] = data['emotions'].str.strip('[')\n","    data['emotions'] = data['emotions'].str.strip(']')\n","    data['emotions'] = data['emotions'].str.replace(\" \", \"\")\n","    data['emotions'] = data['emotions'].str.split(',')\n","    emotion = data['emotions']\n","\n","    emotionTest = data['emotions']\n","    emotionTest = list(set(emotionsTest))\n","\n","    \n","    for i in range(len(tweetText)):\n","\n","        if isinstance(tweetText[i], str):\n","            pMsg = runPrediction(tweetText[i], predict_fn)\n","            sMsg = pMsg.split(\" \")\n","            outMsg = [user[i],tweetText[i]]\n","            for m in sMsg:\n","                if len(m) > 0:\n","                    outMsg.append(m)\n","            csvWriter.writerow(outMsg)\n","\n","if __name__ == \"__main__\":\n","    main()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/predictor/saved_model_predictor.py:153: load (from tensorflow.python.saved_model.loader_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.loader.load or tf.compat.v1.saved_model.load. There will be a new function for importing SavedModels in Tensorflow 2.0.\n","INFO:tensorflow:Restoring parameters from export/1602022423/variables/variables\n"],"name":"stdout"},{"output_type":"error","ename":"NotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)","\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNotFoundError\u001b[0m: export/1602022423/variables/variables.data-00000-of-00002; No such file or directory\n\t [[{{node save/RestoreV2}}]]","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)","\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1289\u001b[0m         sess.run(self.saver_def.restore_op_name,\n\u001b[0;32m-> 1290\u001b[0;31m                  {self.saver_def.filename_tensor_name: save_path})\n\u001b[0m\u001b[1;32m   1291\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1180\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1383\u001b[0m                     'disable_meta_optimizer = True')\n\u001b[0;32m-> 1384\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNotFoundError\u001b[0m: export/1602022423/variables/variables.data-00000-of-00002; No such file or directory\n\t [[node save/RestoreV2 (defined at /tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/ops.py:1748) ]]\n\nOriginal stack trace for 'save/RestoreV2':\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py\", line 664, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py\", line 499, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.6/asyncio/base_events.py\", line 438, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.6/asyncio/base_events.py\", line 1451, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n    handler_func(fileobj, events)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 462, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 492, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 444, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-9-1f052c41f872>\", line 71, in <module>\n    main()\n  File \"<ipython-input-9-1f052c41f872>\", line 47, in main\n    predict_fn = predictor.from_saved_model(\"export/1602022423\")\n  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/contrib/predictor/predictor_factories.py\", line 153, in from_saved_model\n    config=config)\n  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/contrib/predictor/saved_model_predictor.py\", line 153, in __init__\n    loader.load(self._session, tags.split(','), export_dir)\n  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/util/deprecation.py\", line 324, in new_func\n    return func(*args, **kwargs)\n  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/saved_model/loader_impl.py\", line 269, in load\n    return loader.load(sess, tags, import_scope, **saver_kwargs)\n  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/saved_model/loader_impl.py\", line 422, in load\n    **saver_kwargs)\n  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/saved_model/loader_impl.py\", line 352, in load_graph\n    meta_graph_def, import_scope=import_scope, **saver_kwargs)\n  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/training/saver.py\", line 1477, in _import_meta_graph_with_return_elements\n    **kwargs))\n  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/meta_graph.py\", line 809, in import_scoped_meta_graph_with_return_elements\n    return_elements=return_elements)\n  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/importer.py\", line 405, in import_graph_def\n    producer_op_list=producer_op_list)\n  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/importer.py\", line 517, in _import_graph_def_internal\n    _ProcessNewOps(graph)\n  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/importer.py\", line 243, in _ProcessNewOps\n    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\n  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/ops.py\", line 3561, in _add_new_tf_operations\n    for c_op in c_api_util.new_tf_operations(self)\n  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/ops.py\", line 3561, in <listcomp>\n    for c_op in c_api_util.new_tf_operations(self)\n  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/ops.py\", line 3451, in _create_op_from_tf_operation\n    ret = Operation(c_op, self)\n  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/ops.py\", line 1748, in __init__\n    self._traceback = tf_stack.extract_stack()\n","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)","\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1299\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1300\u001b[0;31m         \u001b[0mnames_to_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobject_graph_key_mapping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1301\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNotFoundError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/training/saver.py\u001b[0m in \u001b[0;36mobject_graph_key_mapping\u001b[0;34m(checkpoint_path)\u001b[0m\n\u001b[1;32m   1617\u001b[0m   \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNewCheckpointReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1618\u001b[0;31m   \u001b[0mobject_graph_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrackable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOBJECT_GRAPH_PROTO_KEY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1619\u001b[0m   \u001b[0mobject_graph_proto\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrackable_object_graph_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrackableObjectGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36mget_tensor\u001b[0;34m(self, tensor_str)\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mCheckpointReader_GetTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNotFoundError\u001b[0m: Key _CHECKPOINTABLE_OBJECT_GRAPH not found in checkpoint","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-1f052c41f872>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-9-1f052c41f872>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mcsvWriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriterow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheadCats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;31m#load trained model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0mpredict_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"export/1602022423\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'reddit_hot_NNN_v7.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/contrib/predictor/predictor_factories.py\u001b[0m in \u001b[0;36mfrom_saved_model\u001b[0;34m(export_dir, signature_def_key, signature_def, input_names, output_names, tags, graph, config)\u001b[0m\n\u001b[1;32m    151\u001b[0m       \u001b[0mtags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mgraph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       config=config)\n\u001b[0m","\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/contrib/predictor/saved_model_predictor.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, export_dir, signature_def_key, signature_def, input_names, output_names, tags, graph, config)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexport_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput_names\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/saved_model/loader_impl.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(sess, tags, export_dir, import_scope, **saver_kwargs)\u001b[0m\n\u001b[1;32m    267\u001b[0m   \"\"\"\n\u001b[1;32m    268\u001b[0m   \u001b[0mloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSavedModelLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimport_scope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msaver_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/saved_model/loader_impl.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, sess, tags, import_scope, **saver_kwargs)\u001b[0m\n\u001b[1;32m    421\u001b[0m       saver, _ = self.load_graph(sess.graph, tags, import_scope,\n\u001b[1;32m    422\u001b[0m                                  **saver_kwargs)\n\u001b[0;32m--> 423\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimport_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_init_ops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimport_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_meta_graph_def_from_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/saved_model/loader_impl.py\u001b[0m in \u001b[0;36mrestore_variables\u001b[0;34m(self, sess, saver, import_scope)\u001b[0m\n\u001b[1;32m    375\u001b[0m                         \"checkpoints were restored.\")\n\u001b[1;32m    376\u001b[0m       \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf_saver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSaver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m         \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variables_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m         raise ValueError(\n","\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1304\u001b[0m         \u001b[0;31m# a helpful message (b/110263146)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1305\u001b[0m         raise _wrap_restore_error_with_msg(\n\u001b[0;32m-> 1306\u001b[0;31m             err, \"a Variable name or other graph key that is missing\")\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m       \u001b[0;31m# This is an object-based checkpoint. We'll print a warning and then do\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNotFoundError\u001b[0m: Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n\nexport/1602022423/variables/variables.data-00000-of-00002; No such file or directory\n\t [[node save/RestoreV2 (defined at /tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/ops.py:1748) ]]\n\nOriginal stack trace for 'save/RestoreV2':\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py\", line 664, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py\", line 499, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.6/asyncio/base_events.py\", line 438, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.6/asyncio/base_events.py\", line 1451, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n    handler_func(fileobj, events)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 462, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 492, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 444, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-9-1f052c41f872>\", line 71, in <module>\n    main()\n  File \"<ipython-input-9-1f052c41f872>\", line 47, in main\n    predict_fn = predictor.from_saved_model(\"export/1602022423\")\n  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/contrib/predictor/predictor_factories.py\", line 153, in from_saved_model\n    config=config)\n  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/contrib/predictor/saved_model_predictor.py\", line 153, in __init__\n    loader.load(self._session, tags.split(','), export_dir)\n  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/util/deprecation.py\", line 324, in new_func\n    return func(*args, **kwargs)\n  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/saved_model/loader_impl.py\", line 269, in load\n    return loader.load(sess, tags, import_scope, **saver_kwargs)\n  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/saved_model/loader_impl.py\", line 422, in load\n    **saver_kwargs)\n  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/saved_model/loader_impl.py\", line 352, in load_graph\n    meta_graph_def, import_scope=import_scope, **saver_kwargs)\n  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/training/saver.py\", line 1477, in _import_meta_graph_with_return_elements\n    **kwargs))\n  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/meta_graph.py\", line 809, in import_scoped_meta_graph_with_return_elements\n    return_elements=return_elements)\n  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/importer.py\", line 405, in import_graph_def\n    producer_op_list=producer_op_list)\n  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/importer.py\", line 517, in _import_graph_def_internal\n    _ProcessNewOps(graph)\n  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/importer.py\", line 243, in _ProcessNewOps\n    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\n  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/ops.py\", line 3561, in _add_new_tf_operations\n    for c_op in c_api_util.new_tf_operations(self)\n  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/ops.py\", line 3561, in <listcomp>\n    for c_op in c_api_util.new_tf_operations(self)\n  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/ops.py\", line 3451, in _create_op_from_tf_operation\n    ret = Operation(c_op, self)\n  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/ops.py\", line 1748, in __init__\n    self._traceback = tf_stack.extract_stack()\n"]}]},{"cell_type":"markdown","metadata":{"id":"jSp_pUYCuint"},"source":["Train the estimator"]},{"cell_type":"code","metadata":{"id":"toOAzQ2fsZP6","colab":{"base_uri":"https://localhost:8080/","height":561},"executionInfo":{"status":"error","timestamp":1611196076711,"user_tz":480,"elapsed":464,"user":{"displayName":"Sanghyun Suh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUdCPmMsqijTthZ24MFHldVLUgCbJtwxfzXlusFw=s64","userId":"03325525587695274031"}},"outputId":"4524f4ab-f994-4752-9270-875608a012be"},"source":["import numpy as np\n","import pandas as pd\n","import os\n","import tensorflow as tf\n","import tensorflow_hub as hub\n","from ast import literal_eval\n","from sklearn.preprocessing import MultiLabelBinarizer\n","\n","\n","\n","def main():\n","\n","\n","    data = pd.read_csv('twitter_emotions.csv', header = 0)\n","    np.random.shuffle(data.values[1:, :])\n","    data.head()\n","    descriptions = data['twitter_emotion']\n","    data['emotion'] = data['emotion'].str.strip('[')\n","    data['emotion'] = data['emotion'].str.strip(']')\n","    data['emotion'] = data['emotion'].str.replace(\" \", \"\")\n","    data['emotion'] = data['emotion'].str.split(',')\n","\n","    emotion = data['user']\n","\n","\n","\n","    top_emotions = [\"Anger\",\"Anticipation\",\"Disgust\",\"Joy\"]\n","    print(len(top_emotions))\n","    train_size = int(len(descriptions)* .8)\n","    train_descriptions = descriptions[:train_size].astype('str')\n","    train_emotions = emotion[:train_size]\n","\n","    test_descriptions = descriptions[train_size:].astype('str')\n","    test_emotions = emotion[train_size:]\n","\n","    description_embeddings = hub.text_embedding_column(\n","      \"tweetText\",\n","      module_spec=\"https://tfhub.dev/google/universal-sentence-encoder-large/3\"\n","    )\n","\n","    encoder = MultiLabelBinarizer()\n","    encoder.fit_transform(train_emotions)\n","    train_encoded = encoder.transform(train_emotions)\n","    test_encoded = encoder.transform(test_emotions)\n","    num_classes = len(encoder.classes_)\n","    print(num_classes)\n","    print(encoder.classes_)\n","    print(train_encoded[0])\n","\n","    multi_label_head = tf.contrib.estimator.multi_label_head(\n","        num_classes,\n","        loss_reduction=tf.losses.Reduction.SUM_OVER_BATCH_SIZE\n","    )\n","\n","    feature_columns = [description_embeddings]\n","    estimator = tf.estimator.DNNEstimator(\n","        head=multi_label_head,\n","        hidden_units=[64,10],\n","        feature_columns=feature_columns,\n","        model_dir='models/twitterEmot'\n","    )\n","\n","    # Format our data for the numpy_input_fn\n","    features = {\n","      'tweetText': np.array(train_descriptions)\n","    }\n","    labels = np.array(train_encoded)\n","\n","    train_input_fn = tf.estimator.inputs.numpy_input_fn(\n","        features,\n","        labels,\n","        shuffle=True,\n","        batch_size=32,\n","        num_epochs=200,\n","    )\n","\n","\n","    estimator.train(input_fn=train_input_fn)\n","    feature_spec = tf.feature_column.make_parse_example_spec(feature_columns)\n","    print(feature_spec)\n","    # Build receiver function, and export.\n","    serving_input_receiver_fn = tf.estimator.export.build_parsing_serving_input_receiver_fn(feature_spec)\n","    export_dir = estimator.export_savedmodel('export', serving_input_receiver_fn)\n","\n","    eval_input_fn = tf.estimator.inputs.numpy_input_fn({\"tweetText\": np.array(test_descriptions).astype(np.str)}, test_encoded.astype(np.int32), shuffle=False)\n","\n","    estimator.evaluate(input_fn=eval_input_fn)\n","    raw_test = [\n","        \"This stupid machine never works.\",\n","        # Documentary\n","        \"I really like ice cream\",\n","        # Action, Adventure\n","        \"I'm afraid of spiders\",\n","        # Comedy\n","    ]\n","    # Generate predictions\n","    predict_input_fn = tf.estimator.inputs.numpy_input_fn({\"tweetText\": np.array(raw_test).astype(np.str)}, shuffle=False)\n","    results = estimator.predict(predict_input_fn)\n","    mCnt = 0\n","    for tweetEmotions in results:\n","        print(raw_test[mCnt].encode(encoding='UTF-8'))\n","        top_2 = tweetEmotions['probabilities'].argsort()[-2:][::-1]\n","        for emot in top_2:\n","            text_emot = encoder.classes_[emot]\n","            print(text_emot + ': ' + str(round(tweetEmotions['probabilities'][emot] * 100, 2)) + '%')\n","        print('')\n","        mCnt = mCnt + 1\n","\n","if __name__ == \"__main__\":\n","    main()"],"execution_count":null,"outputs":[{"output_type":"error","ename":"KeyError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2897\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2898\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2899\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'twitter_emotion'","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-4551d3c2561a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-7-4551d3c2561a>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mdescriptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'twitter_emotion'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'emotion'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'emotion'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'['\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'emotion'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'emotion'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m']'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2904\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2905\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2906\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2907\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2908\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2898\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2900\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2902\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'twitter_emotion'"]}]},{"cell_type":"code","metadata":{"id":"KvMEQlB2u9xT"},"source":[""],"execution_count":null,"outputs":[]}]}